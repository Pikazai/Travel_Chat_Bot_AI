"""
Core chat engine for handling conversations and AI interactions.
"""
from typing import List, Dict, Optional
import openai
from config.settings import get_settings
from services.chroma_service import ChromaService
from services.weather_service import WeatherService
from services.places_service import PlacesService
from utils.extractors import extract_city_and_dates, extract_days_from_text


class ChatEngine:
    """Core engine for handling chatbot conversations."""
    
    def __init__(self):
        """Initialize the chat engine."""
        settings = get_settings()
        self.settings = settings
        self.client = None
        self.chroma_service = ChromaService()
        self.weather_service = WeatherService()
        self.places_service = PlacesService()
        
        # Initialize OpenAI client
        if settings.OPENAI_API_KEY:
            try:
                self.client = openai.OpenAI(
                    base_url=settings.OPENAI_ENDPOINT,
                    api_key=settings.OPENAI_API_KEY
                )
                # Set client for services that need it
                self.weather_service.set_openai_client(self.client)
                self.places_service.set_openai_client(self.client)
            except Exception:
                pass
    
    def generate_suggestions(self, limit: int = 4) -> List[str]:
        """
        Generate suggested questions for the user.
        
        Args:
            limit: Number of suggestions to generate
            
        Returns:
            List of suggested questions
        """
        if not self.client:
            return [
                "Thá»i tiáº¿t á»Ÿ ÄÃ  Náºµng tuáº§n tá»›i?",
                "Top mÃ³n Äƒn á»Ÿ Huáº¿?",
                "Lá»‹ch trÃ¬nh 3 ngÃ y á»Ÿ Nha Trang?",
                "CÃ³ sá»± kiá»‡n gÃ¬ á»Ÿ HÃ  Ná»™i thÃ¡ng 12?"
            ]
        
        try:
            prompt = f"""
Báº¡n lÃ  {self.settings.CHATBOT_NAME} â€“ {self.settings.SYSTEM_PROMPT.strip()}
HÃ£y táº¡o {limit} cÃ¢u há»i gá»£i Ã½ (ngáº¯n gá»n, thÃ¢n thiá»‡n) Ä‘á»ƒ ngÆ°á»i dÃ¹ng cÃ³ thá»ƒ há»i báº¡n.
Tráº£ vá» dÆ°á»›i dáº¡ng danh sÃ¡ch (list) cÃ¡c chuá»—i.
"""
            response = self.client.chat.completions.create(
                model=self.settings.DEPLOYMENT_NAME,
                messages=[{"role": "system", "content": prompt}],
                max_tokens=200,
                temperature=0.7
            )
            text = response.choices[0].message.content.strip()
            # Try to parse JSON list
            import json
            import re
            try:
                data = json.loads(text)
                if isinstance(data, list) and all(isinstance(x, str) for x in data):
                    return [s.strip() for s in data][:limit]
            except Exception:
                pass
            
            # Fallback parsing
            m = re.search(r'\[.*\]', text, re.DOTALL)
            if m:
                list_text = m.group(0)
                try:
                    fixed = list_text.replace("'", '"')
                    data = json.loads(fixed)
                    if isinstance(data, list):
                        return [s.strip() for s in data if isinstance(s, str)][:limit]
                except Exception:
                    pass
            
            # Return default if parsing fails
            return [
                "Thá»i tiáº¿t á»Ÿ ÄÃ  Náºµng tuáº§n tá»›i?",
                "Top mÃ³n Äƒn á»Ÿ Huáº¿?",
                "Lá»‹ch trÃ¬nh 3 ngÃ y á»Ÿ Nha Trang?",
                "CÃ³ sá»± kiá»‡n gÃ¬ á»Ÿ HÃ  Ná»™i thÃ¡ng 12?"
            ]
        except Exception:
            return [
                "Thá»i tiáº¿t á»Ÿ ÄÃ  Náºµng tuáº§n tá»›i?",
                "Top mÃ³n Äƒn á»Ÿ Huáº¿?",
                "Lá»‹ch trÃ¬nh 3 ngÃ y á»Ÿ Nha Trang?",
                "CÃ³ sá»± kiá»‡n gÃ¬ á»Ÿ HÃ  Ná»™i thÃ¡ng 12?"
            ]
    
    def process_message(
        self,
        user_input: str,
        conversation_history: List[Dict[str, str]],
        use_rag: bool = True,
        use_cache: bool = True,
        rag_k: int = 6
    ) -> Dict[str, any]:
        """
        Process a user message and generate a response.
        
        Args:
            user_input: User's input text
            conversation_history: Previous conversation messages
            use_rag: Whether to use RAG for context retrieval
            use_cache: Whether to use semantic cache
            rag_k: Number of RAG results to retrieve
            
        Returns:
            Dictionary with response and extracted information
        """
        # Extract city and dates
        city, start_date, end_date = extract_city_and_dates(user_input, self.client)
        days = extract_days_from_text(user_input, start_date, end_date, self.client)
        
        # Build messages for LLM
        messages_for_llm = list(conversation_history)
        
        # Add RAG context if enabled
        context_block = ""
        if self.chroma_service.is_available() and use_rag:
            rag_items = self.chroma_service.retrieve_context(
                user_input,
                city,
                k=rag_k
            )
            if rag_items:
                lines = []
                for it in rag_items:
                    meta = it["meta"]
                    tag = f"{meta.get('type','kb')}/{meta.get('source','')}/{meta.get('city','')}"
                    score = 1.0 - it["dist"]
                    lines.append(f"- [{tag} | simâ‰ˆ{score:.3f}] {it['doc']}")
                context_block = "\n".join(lines)
                messages_for_llm.insert(1, {
                    "role": "system",
                    "content": "Ngá»¯ cáº£nh (Æ°u tiÃªn cao, dÃ¹ng lÃ m nguá»“n sá»± tháº­t):\n" + context_block
                })
        
        # Check semantic cache
        assistant_text = None
        if self.chroma_service.is_available() and use_cache:
            cached_answer = self.chroma_service.hit_answer_cache(user_input, city)
            if cached_answer:
                assistant_text = cached_answer
        
        # Generate response if not cached
        if not assistant_text:
            if self.client:
                try:
                    response = self.client.chat.completions.create(
                        model=self.settings.DEPLOYMENT_NAME,
                        messages=messages_for_llm,
                        max_tokens=900,
                        temperature=0.7
                    )
                    assistant_text = response.choices[0].message.content.strip()
                    
                    # Cache the answer
                    if self.chroma_service.is_available() and use_cache:
                        self.chroma_service.push_answer_cache(user_input, city, assistant_text)
                except Exception as e:
                    assistant_text = f"Xin lá»—i, Ä‘Ã£ xáº£y ra lá»—i: {e}"
            else:
                assistant_text = f"Xin chÃ o! TÃ´i cÃ³ thá»ƒ giÃºp báº¡n vá»›i thÃ´ng tin vá» {city or 'Ä‘á»‹a Ä‘iá»ƒm'} â€” thá»­ há»i 'Thá»i tiáº¿t', 'Äáº·c sáº£n', hoáº·c 'Lá»‹ch trÃ¬nh 3 ngÃ y'."
        
        # Add closing if not present
        if not assistant_text.endswith(("ðŸŒ¤ï¸â¤ï¸", "ðŸ˜Š", "ðŸŒ¸", "ðŸŒ´", "âœ¨")):
            assistant_text += "\n\nChÃºc báº¡n cÃ³ chuyáº¿n Ä‘i vui váº» ðŸŒ¤ï¸â¤ï¸"
        
        # Save conversation to memory
        if self.chroma_service.is_available():
            self.chroma_service.save_conversation(user_input, assistant_text, city)
        
        return {
            "response": assistant_text,
            "city": city,
            "start_date": start_date,
            "end_date": end_date,
            "days": days,
            "context_block": context_block
        }
    
    def estimate_cost(self, city: str, days: int = 3, people: int = 1, style: str = "trung bÃ¬nh") -> str:
        """
        Estimate travel cost.
        
        Args:
            city: City name
            days: Number of days
            people: Number of people
            style: Travel style (tiáº¿t kiá»‡m, trung bÃ¬nh, cao cáº¥p)
            
        Returns:
            Cost estimate text
        """
        mapping = {
            "tiáº¿t kiá»‡m": 400000,
            "trung bÃ¬nh": 800000,
            "cao cáº¥p": 2000000
        }
        per_day = mapping.get(style, 800000)
        total = per_day * days * people
        return f"ðŸ’¸ Chi phÃ­ Æ°á»›c tÃ­nh: khoáº£ng {total:,} VNÄ cho {people} ngÆ°á»i, {days} ngÃ y."
    
    def suggest_events(self, city: str) -> str:
        """Generate event suggestions for a city."""
        return f"ðŸŽ‰ Sá»± kiá»‡n á»Ÿ {city}: lá»… há»™i Ä‘á»‹a phÆ°Æ¡ng, chá»£ Ä‘Ãªm, há»™i chá»£ áº©m thá»±c (tuá»³ mÃ¹a)."

