# Travel_Chat_Bot_Enhanced_VOICE_RAG_fixed2.py
# =================================
# M·ªü r·ªông: RAG (ChromaDB) + long-term memory + intent quick-match + recommendations
# Gi·ªØ l·∫°i to√†n b·ªô ch·ª©c nƒÉng g·ªëc (voice, TTS, weather, map, foods, restaurants...)
#
# Y√™u c·∫ßu:
#   pip install streamlit-mic-recorder SpeechRecognition pydub gTTS chromadb openai geopy pandas pydeck plotly sentence-transformers
#   C√†i ffmpeg cho pydub
#

import streamlit as st
import openai
import json
import requests
import os
from datetime import datetime, timedelta
from geopy.geocoders import Nominatim
import pandas as pd
import sqlite3
import pydeck as pdk
import re
import time
import plotly.express as px

# === VOICE imports (m·ªõi) ===
import io
import base64
import tempfile
import subprocess
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr
from pydub import AudioSegment   # y√™u c·∫ßu ffmpeg
from gtts import gTTS

# === RAG / Chroma imports ===
from chromadb import PersistentClient
# NOTE: Replaced Client->PersistentClient for Chroma v1.2+# Chroma v1.2+ no longer uses chromadb.config.Settings
import uuid

# === TH√äM IMPORTS CHO EMBEDDING LOCAL ===
from sentence_transformers import SentenceTransformer
import numpy as np

# === KHAI B√ÅO MODEL EMBEDDING LOCAL ===
# === KHAI B√ÅO MODEL EMBEDDING LOCAL ===
@st.cache_resource
def load_embedding_model():
    try:
        # Th·ª≠ t·∫£i t·ª´ th∆∞ m·ª•c local tr∆∞·ªõc, n·∫øu kh√¥ng c√≥ th√¨ t·∫£i t·ª´ Hugging Face
        model_path = "data/all-MiniLM-L6-v2"
        if os.path.exists(model_path) and os.path.isdir(model_path):
            # Ki·ªÉm tra xem th∆∞ m·ª•c c√≥ ch·ª©a model kh√¥ng
            if any(file.endswith('model.safetensors') for file in os.listdir(model_path)):
                model = SentenceTransformer(model_path)
                print("‚úÖ ƒê√£ t·∫£i model embedding local: all-MiniLM-L6-v2")
                return model
        
        # N·∫øu kh√¥ng c√≥ model local, t·∫£i t·ª´ Hugging Face
        print("üì• ƒêang t·∫£i model t·ª´ Hugging Face...")
        model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')
        
        # L∆∞u model v√†o th∆∞ m·ª•c local ƒë·ªÉ l·∫ßn sau d√πng
        os.makedirs(model_path, exist_ok=True)
        model.save(model_path)
        print(f"‚úÖ ƒê√£ t·∫£i v√† l∆∞u model v√†o: {model_path}")
        return model
    except Exception as e:
        print(f"‚ùå L·ªói khi t·∫£i model embedding: {e}")
        return None

# Load model
embedding_model = load_embedding_model()

# === Ensure single persistent Chroma client in Streamlit session ===
CHROMA_PERSIST_DIR = os.getenv("CHROMA_PERSIST_DIR", "chromadb_data")
# We'll create chroma_client lazily in init_chroma(), but ensure session key exists placeholder
# Actual ChromaClient will be created inside init_chroma using this CHROMA_PERSIST_DIR.

# -------------------------
st.set_page_config(page_title="[M√¢y Lang Thang] - Travel Assistant (Voice + RAG)", layout="wide", page_icon="üå§Ô∏è")

# Global CSS + UI tweaks
st.markdown(
    """
    <style>
    :root{
      --primary:#2b4c7e;
      --accent:#e7f3ff;
      --muted:#f2f6fa;
    }
    body {
      background: linear-gradient(90deg, #f8fbff 0%, #eef5fa 100%);
      font-family: 'Segoe UI', Roboto, Arial, sans-serif;
    }
    .stApp > header {visibility: hidden;}
    h1, h2, h3 { color: var(--primary); }
    .sidebar-card { background-color:#f1f9ff; padding:10px; border-radius:10px; margin-bottom:8px;}
    .user-message { background: #f2f2f2; padding:10px; border-radius:12px; }
    .assistant-message { background: #e7f3ff; padding:10px; border-radius:12px; }
    .pill-btn { border-radius:999px !important; background:#e3f2fd !important; color:var(--primary) !important; padding:6px 12px; border: none; }
    .status-ok { background:#d4edda; padding:8px; border-radius:8px; }
    .status-bad { background:#f8d7da; padding:8px; border-radius:8px; }
    .small-muted { color: #6b7280; font-size:12px; }
    .logo-title { display:flex; align-items:center; gap:10px; }
    .logo-title h1 { margin:0; }
    .assistant-bubble {
      background-color: #e7f3ff;
      padding: 12px 16px;
      border-radius: 15px;
      margin-bottom: 6px;
    }
    .user-message {
      background-color: #f2f2f2;
      padding: 12px 16px;
      border-radius: 15px;
      margin-bottom: 6px;
    }
    .source-badge {
      background: #e8f5e8;
      border: 1px solid #4caf50;
      border-radius: 12px;
      padding: 8px 12px;
      margin: 5px 0;
      font-size: 0.85em;
    }
    .source-chroma {
      background: #e3f2fd;
      border-left: 4px solid #2196f3;
    }
    .source-intent {
      background: #fff3e0;
      border-left: 4px solid #ff9800;
    }
    .source-memory {
      background: #f3e5f5;
      border-left: 4px solid #9c27b0;
    }
    /* HERO */
    .hero {
      position: relative;
      border-radius: 16px;
      overflow: hidden;
      box-shadow: 0 8px 30px rgba(43,76,126,0.12);
      margin-bottom: 18px;
    }
    .hero__bg {
      width: 100%;
      height: 320px;
      object-fit: cover;
      filter: brightness(0.65) saturate(1.05);
    }
    .hero__overlay {
      position: absolute;
      top: 0; left: 0; right: 0; bottom: 0;
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 24px;
    }
    .hero__card {
      background: linear-gradient(90deg, rgba(255,255,255,0.02), rgba(255,255,255,0.08));
      backdrop-filter: blur(6px);
      border-radius: 12px;
      padding: 18px;
      width: 100%;
      max-width: 980px;
      color: white;
    }
    .hero__title { font-size: 28px; font-weight:700; margin:0 0 6px 0; color: #fff; }
    .hero__subtitle { margin:0 0 12px 0; color: #f0f6ff; }
    .hero__cta { display:flex; gap:8px; align-items:center; }
    @media (max-width: 768px) {
      .hero__bg { height: 220px; }
      .hero__title { font-size: 20px; }
    }
    .audio-wrapper {margin-top: 6px;}
    </style>
    """, unsafe_allow_html=True
)

# -------------------------
# CONFIG / SECRETS
# -------------------------
try:
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
except Exception:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", None)
OPENAI_ENDPOINT = st.secrets.get("OPENAI_ENDPOINT", "https://api.openai.com/v1") if hasattr(st, 'secrets') else os.getenv("OPENAI_ENDPOINT", "https://api.openai.com/v1")
DEPLOYMENT_NAME = st.secrets.get("DEPLOYMENT_NAME", "gpt-4o-mini") if hasattr(st, 'secrets') else os.getenv("DEPLOYMENT_NAME", "gpt-4o-mini")
OPENWEATHERMAP_API_KEY = st.secrets.get("OPENWEATHERMAP_API_KEY", "") if hasattr(st, 'secrets') else os.getenv("OPENWEATHERMAP_API_KEY", "")
GOOGLE_PLACES_KEY = st.secrets.get("PLACES_API_KEY", "") if hasattr(st, 'secrets') else os.getenv("PLACES_API_KEY", "")
PIXABAY_API_KEY = st.secrets.get("PIXABAY_API_KEY", "") if hasattr(st, 'secrets') else os.getenv("PIXABAY_API_KEY", "")

# Chroma persistent dir (t√πy ch·ªçn)
CHROMA_PERSIST_DIR = os.getenv("CHROMA_PERSIST_DIR", "chromadb_data")

# Initialize OpenAI client (using openai Python SDK modern interface)
if OPENAI_API_KEY:
    client = openai.OpenAI(base_url=OPENAI_ENDPOINT, api_key=OPENAI_API_KEY)
else:
    client = None

ChatBotName = "[M√¢y Lang Thang]"  # display name
system_prompt1 = """
B·∫°n l√† H∆∞·ªõng d·∫´n vi√™n du l·ªãch ·∫£o Alex - ng∆∞·ªùi k·ªÉ chuy·ªán, am hi·ªÉu vƒÉn h√≥a, l·ªãch s·ª≠, ·∫©m th·ª±c v√† th·ªùi ti·∫øt Vi·ªát Nam.
Lu√¥n ƒë∆∞a ra th√¥ng tin h·ªØu √≠ch, g·ª£i √Ω l·ªãch tr√¨nh, m√≥n ƒÉn, chi ph√≠, th·ªùi gian l√Ω t∆∞·ªüng, s·ª± ki·ªán v√† g√≥c ch·ª•p ·∫£nh.
"""

system_prompt = """  
B·∫°n l√† H∆∞·ªõng d·∫´n vi√™n du l·ªãch ·∫£o "Alex" - chuy√™n gia am hi·ªÉu s√¢u s·∫Øc v·ªÅ vƒÉn h√≥a, l·ªãch s·ª≠, ·∫©m th·ª±c v√† kh√≠ h·∫≠u Vi·ªát Nam.

**VAI TR√í V√Ä TR√ÅCH NHI·ªÜM:**
- Cung c·∫•p th√¥ng tin du l·ªãch ch√≠nh x√°c, h·ªØu √≠ch v√† c·∫≠p nh·∫≠t
- K·ªÉ chuy·ªán l·ªãch s·ª≠, vƒÉn h√≥a m·ªôt c√°ch sinh ƒë·ªông, h·∫•p d·∫´n
- T∆∞ v·∫•n l·ªãch tr√¨nh t·ªëi ∆∞u theo nhu c·∫ßu v√† ng√¢n s√°ch

**KI·∫æN TH·ª®C CHUY√äN S√ÇU:**
- VƒÉn h√≥a & phong t·ª•c c√°c v√πng mi·ªÅn
- L·ªãch s·ª≠ & di s·∫£n UNESCO
- ·∫®m th·ª±c ƒë·∫∑c tr∆∞ng t·ª´ng ƒë·ªãa ph∆∞∆°ng
- Kh√≠ h·∫≠u & th·ªùi ƒëi·ªÉm du l·ªãch l√Ω t∆∞·ªüng
- S·ª± ki·ªán vƒÉn h√≥a, l·ªÖ h·ªôi truy·ªÅn th·ªëng

**PHONG C√ÅCH GIAO TI·∫æP:**
- Th√¢n thi·ªán, nhi·ªát t√¨nh, chu ƒë√°o
- K·ªÉ chuy·ªán sinh ƒë·ªông nh∆∞ ng∆∞·ªùi d·∫´n tour th·ª±c th·ª•
- C√¢n b·∫±ng gi·ªØa th√¥ng tin h·ªØu √≠ch v√† y·∫øu t·ªë gi·∫£i tr√≠
- Lu√¥n h·ªèi l·∫°i ƒë·ªÉ hi·ªÉu r√µ nhu c·∫ßu c·ª• th·ªÉ c·ªßa kh√°ch

**ƒê·ªäNH D·∫†NG TH√îNG TIN KHI T∆Ø V·∫§N:**
1. üìç **ƒê·ªãa ƒëi·ªÉm**: T√™n + ƒë·∫∑c ƒëi·ªÉm n·ªïi b·∫≠t
2. ‚è∞ **Th·ªùi gian**: Th·ªùi ƒëi·ªÉm l√Ω t∆∞·ªüng + th·ªùi gian tham quan
3. üçú **·∫®m th·ª±c**: M√≥n ngon ƒë·∫∑c tr∆∞ng + ƒë·ªãa ch·ªâ
4. üí∞ **Chi ph√≠**: ∆Ø·ªõc t√≠nh ng√¢n s√°ch
5. üì∏ **G√≥c ch·ª•p**: V·ªã tr√≠ ch·ª•p ·∫£nh ƒë·∫πp
6. üéØ **M·∫πo hay**: Kinh nghi·ªám th·ª±c t·∫ø

**L∆ØU √ù QUAN TR·ªåNG:**
- Lu√¥n ƒë·ªÅ xu·∫•t c√°c l·ª±a ch·ªçn ph√π h·ª£p v·ªõi ng√¢n s√°ch
- Nh·∫•n m·∫°nh c√°c quy t·∫Øc ·ª©ng x·ª≠ vƒÉn h√≥a
- C·∫£nh b√°o v·ªÅ c√°c m√πa du l·ªãch ƒë√¥ng ƒë√∫c
- G·ª£i √Ω c√°c tr·∫£i nghi·ªám off-the-beaten-path

"""

# -------------------------
# DB LOGGING (SQLite) - ƒê√É S·ª¨A SCHEMA
# -------------------------
DB_PATH = "travel_chatbot_logs.db"

def init_db():
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS interactions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp TEXT,
            user_input TEXT,
            city TEXT,
            start_date TEXT,
            end_date TEXT,
            intent TEXT,
            rag_used BOOLEAN DEFAULT 0,
            sources_count INTEGER DEFAULT 0
        )
    """)
    conn.commit()
    conn.close()

init_db()

def log_interaction(user_input, city=None, start_date=None, end_date=None, intent=None, rag_used=False, sources_count=0):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("""
        INSERT INTO interactions (timestamp, user_input, city, start_date, end_date, intent, rag_used, sources_count)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?)
    """, (datetime.utcnow().isoformat(), user_input, city,
          start_date.isoformat() if start_date else None,
          end_date.isoformat() if end_date else None,
          intent, rag_used, sources_count))
    conn.commit()
    conn.close()

# -------------------------
# Optional: seeding vietnam_travel collection from CSV
# -------------------------
def seed_vietnam_travel_from_csv(path="data/vietnam_travel_docs.csv"):
    if chroma_travel_col is None:
        print("Chroma travel collection not ready")
        return False
    if not os.path.exists(path):
        print("Seed file not found:", path)
        return False
    try:
        docs = []
        metas = []
        ids = []
        import csv
        with open(path, newline='', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                text = row.get("text") or row.get("description") or ""
                docs.append(text)
                metas.append({"title": row.get("title",""), "city": row.get("city",""), "source": row.get("source","")})
                ids.append(row.get("id") or f"doc_{uuid.uuid4().hex[:8]}")
        chroma_travel_col.add(documents=docs, metadatas=metas, ids=ids)
        print(f"Seeded {len(docs)} docs to vietnam_travel")
        return True
    except Exception as e:
        print("Seed error:", e)
        return False

# -------------------------
# EMBEDDING LOCAL FUNCTION
# -------------------------
def get_embedding_local(text):
    """
    Tr·∫£ v·ªÅ embedding s·ª≠ d·ª•ng model local all-MiniLM-L6-v2 (384 dimensions)
    """
    if embedding_model is None:
        return None
    try:
        # Chu·∫©n h√≥a text
        if not text or not isinstance(text, str):
            return None
        
        # Encode text th√†nh embedding
        embedding = embedding_model.encode(text)
        
        # Convert numpy array to list
        if hasattr(embedding, 'tolist'):
            return embedding.tolist()
        return list(embedding)
    except Exception as e:
        print(f"[WARN] Local embedding failed: {e}")
        return None

# -------------------------
# CHROMA (RAG + Memory + Intent) INIT
# -------------------------

def safe_get_collection(client, name, expected_dim=384):
    """
    Create or get a Chroma collection safely.
    Auto recreate collection if dimension mismatch or corruption occurs.
    Compatible with Chroma v1.2+ PersistentClient.
    """
    try:
        col = None
        try:
            col = client.get_collection(name)
        except Exception:
            # if get_collection not available, try get_or_create_collection
            try:
                col = client.get_or_create_collection(name=name)
            except Exception:
                pass
        if col is None:
            try:
                col = client.create_collection(name=name)
            except Exception:
                # fallback to get_or_create
                try:
                    col = client.get_or_create_collection(name=name)
                except Exception:
                    return None
        # Probe dimension by attempting a harmless query with expected_dim; delete if mismatch
        try:
            test_emb = [0.0] * expected_dim
            try:
                # newer chroma expects embeddings param name 'query_embeddings' or 'embeddings' depending on version
                col.query(query_embeddings=[test_emb], n_results=1)
            except Exception as qe:
                msg = str(qe).lower()
                if "dimension" in msg or "expected" in msg:
                    try:
                        print(f"üßπ Deleting collection {name} due to embedding-dimension mismatch ({qe})")
                        client.delete_collection(name=name)
                        # recreate
                        col = client.create_collection(name=name)
                    except Exception as de:
                        print(f"[WARN] Failed deleting/recreating collection {name}: {de}")
        except Exception:
            pass
        return col
    except Exception as e:
        print(f"[WARN] safe_get_collection failed for {name}: {e}")
        return None

def init_chroma():
    """
    Initialize Chroma persistent client and ensure collections exist.
    Compatible with Chroma v1.2+ using PersistentClient.
    """
    global chroma_client, chroma_travel_col, chroma_memory_col, chroma_intent_col
    EXPECTED_DIM = 384  # ƒê√É THAY ƒê·ªîI: all-MiniLM-L6-v2 c√≥ 384 dimensions
    
    # persist dir (project-local)
    persist_dir = os.path.join(os.getcwd(), "chromadb_data")
    try:
        # Use PersistentClient for new Chroma versions
        from chromadb import PersistentClient
        # create or reuse client in st.session_state
        if "chroma_client" not in st.session_state or st.session_state.get("chroma_client") is None:
            st.session_state["chroma_client"] = PersistentClient(path=persist_dir)
            print("[INIT] Created PersistentClient for Chroma at", persist_dir)
        else:
            print("[DEBUG] Reusing existing PersistentClient in session_state")
        chroma_client = st.session_state["chroma_client"]
    except Exception as e:
        print(f"[WARN] Failed to init PersistentClient: {e}")
        try:
            # fallback: try to use PersistentClient directly without session_state
            chroma_client = PersistentClient(path=persist_dir)
        except Exception as e2:
            print(f"[ERROR] PersistentClient fallback failed: {e2}")
            return None, None, None, None
    # --- Force scan and delete any 1536-dimension collections ---
    try:
        for col in chroma_client.list_collections():
            cname = getattr(col, "name", str(col))
            try:
                emb = [0.0] * EXPECTED_DIM
                col.query(query_embeddings=[emb], n_results=1)
            except Exception as qe:
                if "1536" in str(qe):
                    print(f"üßπ Force deleting old collection {cname} (1536-dim detected)")
                    try:
                        chroma_client.delete_collection(name=cname)
                    except Exception as de:
                        print(f"[WARN] Could not delete old collection {cname}: {de}")
    except Exception as e:
        print(f"[WARN] Force cleanup skipped: {e}")

    # ensure persist dir exists
    try:
        os.makedirs(persist_dir, exist_ok=True)
    except Exception:
        pass

    # create/get our important collections
    travel_col = safe_get_collection(chroma_client, "vietnam_travel_v2", expected_dim=EXPECTED_DIM)
    memory_col = safe_get_collection(chroma_client, "chat_memory_v2", expected_dim=EXPECTED_DIM)
    intent_col = safe_get_collection(chroma_client, "intent_bank_v2", expected_dim=EXPECTED_DIM)

    print("‚úÖ Chroma collections ready (or created):", 
          f"travel={'OK' if travel_col else 'NO'}, memory={'OK' if memory_col else 'NO'}, intent={'OK' if intent_col else 'NO'}")
    print(f"‚úÖ Chroma initialized: travel={bool(travel_col)}, memory={bool(memory_col)}, intent={bool(intent_col)}")
    return chroma_client, travel_col, memory_col, intent_col

# --- Initialize Chroma client and collections once (and store in session_state/global) ---
try:
    chroma_client, chroma_travel_col, chroma_memory_col, chroma_intent_col = init_chroma()
except Exception as e:
    chroma_client = chroma_travel_col = chroma_memory_col = chroma_intent_col = None
    print(f"[WARN] init_chroma() failed: {e}")

# -------------------------
# UTILITIES: days extraction (original logic)
# -------------------------
def extract_days_from_text(user_text, start_date=None, end_date=None):
    if start_date and end_date:
        try:
            delta = (end_date - start_date).days + 1
            return max(delta, 1)
        except Exception:
            pass
    m = re.search(r"(\d+)\s*(ng√†y|day|days|tu·∫ßn|week|weeks)", user_text, re.IGNORECASE)
    if m:
        num = int(m.group(1))
        unit = m.group(2).lower()
        if "tu·∫ßn" in unit or "week" in unit:
            return num * 7
        return num
    if client:
        try:
            prompt = f"""
B·∫°n l√† m·ªôt b·ªô ph√¢n t√≠ch ng·ªØ nghƒ©a ti·∫øng Vi·ªát & ti·∫øng Anh.
X√°c ƒë·ªãnh ng∆∞·ªùi d√πng mu·ªën n√≥i bao nhi√™u ng√†y trong c√¢u sau, n·∫øu kh√¥ng c√≥ th√¨ m·∫∑c ƒë·ªãnh 3:
Tr·∫£ v·ªÅ JSON: {{"days": <s·ªë nguy√™n>}}
C√¢u: "{user_text}"
"""
            response = client.chat.completions.create(
                model=DEPLOYMENT_NAME,
                messages=[{"role": "system", "content": prompt}],
                max_tokens=50,
                temperature=0
            )
            text = response.choices[0].message.content.strip()
            num_match = re.search(r'"days"\s*:\s*(\d+)', text)
            if num_match:
                return int(num_match.group(1))
        except Exception:
            pass
    return 3

# -------------------------
# GEOCODING & MAPS
# -------------------------
geolocator = Nominatim(user_agent="travel_chatbot_app")

def geocode_city(city_name):
    try:
        loc = geolocator.geocode(city_name, country_codes="VN", timeout=10)
        if loc:
            return loc.latitude, loc.longitude, loc.address
        return None, None, None
    except Exception:
        return None, None, None

def show_map(lat, lon, zoom=8, title=""):
    if lat is None or lon is None:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu to·∫° ƒë·ªô ƒë·ªÉ hi·ªÉn th·ªã b·∫£n ƒë·ªì.")
        return

    lat, lon = float(lat), float(lon)

    st.write(f"**V·ªã tr√≠:** {title} ({lat:.5f}, {lon:.5f})")

    view_state = pdk.ViewState(latitude=lat, longitude=lon, zoom=zoom)

    layer = pdk.Layer(
        "ScatterplotLayer",
        data=pd.DataFrame([{"lat": lat, "lon": lon}]),
        get_position='[lon, lat]',
        get_radius=2000,
        get_fill_color=[255, 0, 0],
        get_line_color=[0, 0, 0],
        line_width_min_pixels=1,
        pickable=True,
        opacity=0.9,
    )

    marker_layer = pdk.Layer(
        "TextLayer",
        data=pd.DataFrame([{"lat": lat, "lon": lon, "name": "üìç"}]),
        get_position='[lon, lat]',
        get_text="name",
        get_size=24,
        get_color=[200, 30, 30],
        billboard=True,
    )

    deck = pdk.Deck(
        layers=[layer, marker_layer],
        initial_view_state=view_state,
        map_style="https://basemaps.cartocdn.com/gl/positron-gl-style/style.json",
        tooltip={"text": title or "V·ªã tr√≠"},
    )

    st.pydeck_chart(deck)

# -------------------------
# WEATHER (OpenWeatherMap) with AI fallback on location
# -------------------------
def resolve_city_via_ai(user_text):
    if not client:
        return None
    try:
        prompt = f"""
B·∫°n l√† chuy√™n gia ƒë·ªãa l√Ω du l·ªãch Vi·ªát Nam.
Ph√¢n t√≠ch c√¢u sau ƒë·ªÉ x√°c ƒë·ªãnh:
1. 'place': ƒë·ªãa danh c·ª• th·ªÉ
2. 'province_or_city': t·ªânh/th√†nh c·ªßa Vi·ªát Nam ch·ª©a ƒë·ªãa danh ƒë√≥.
N·∫øu kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c, tr·∫£ v·ªÅ null.
JSON v√≠ d·ª•: {{"place":"Phong Nha - K·∫ª B√†ng","province_or_city":"Qu·∫£ng B√¨nh"}}
C√¢u: "{user_text}"
"""
        response = client.chat.completions.create(
            model=DEPLOYMENT_NAME,
            messages=[{"role": "system", "content": prompt}],
            max_tokens=200,
            temperature=0
        )
        text = response.choices[0].message.content.strip()
        start, end = text.find("{"), text.rfind("}")
        if start == -1 or end == -1:
            return None
        data = json.loads(text[start:end+1])
        return data.get("province_or_city")
    except Exception:
        return None

def get_weather_forecast(city_name, start_date=None, end_date=None, user_text=None):
    if not OPENWEATHERMAP_API_KEY:
        return "‚ö†Ô∏è Thi·∫øu OpenWeatherMap API Key."
    
     # TH√äM: X·ª≠ l√Ω khi kh√¥ng c√≥ ng√†y - l·∫•y ng√†y hi·ªán t·∫°i
    if start_date is None or end_date is None:
        today = datetime.now().date()
        start_date = datetime.combine(today, datetime.min.time())
        end_date = datetime.combine(today, datetime.min.time())
    
    try:
        def _fetch_weather(city):
            url = f"http://api.openweathermap.org/data/2.5/forecast?q={city}&appid={OPENWEATHERMAP_API_KEY}&lang=vi&units=metric"
            response = requests.get(url, timeout=8)
            return response.json()
        data = _fetch_weather(city_name)
        if data.get("cod") != "200" and user_text:
            ai_city = resolve_city_via_ai(user_text)
            if ai_city and ai_city.lower() != city_name.lower():
                data = _fetch_weather(f"{ai_city},VN")
                city_name = ai_city
        if data.get("cod") != "200":
            return f"‚ùå Kh√¥ng t√¨m th·∫•y th√¥ng tin d·ª± b√°o th·ªùi ti·∫øt cho ƒë·ªãa ƒëi·ªÉm: **{city_name}**."
        forecast_text = f"üå§ **D·ª± b√°o th·ªùi ti·∫øt cho {city_name}:**\n"
        if start_date and end_date:
            current = start_date
            while current <= end_date:
                date_str = current.strftime("%Y-%m-%d")
                day_forecasts = [f for f in data['list'] if f['dt_txt'].startswith(date_str)]
                if not day_forecasts:
                    forecast_text += f"\nüìÖ {current.strftime('%d/%m/%Y')}: Kh√¥ng c√≥ d·ªØ li·ªáu d·ª± b√°o.\n"
                else:
                    temps = [f['main']['temp'] for f in day_forecasts]
                    desc = day_forecasts[0]['weather'][0]['description']
                    forecast_text += (
                        f"\nüìÖ {current.strftime('%d/%m/%Y')} - {desc.capitalize()}\n"
                        f"üå° Nhi·ªát ƒë·ªô trung b√¨nh: {sum(temps)/len(temps):.1f}¬∞C\n"
                    )
                current += timedelta(days=1)
        else:
            first_forecast = data['list'][0]
            desc = first_forecast['weather'][0]['description'].capitalize()
            temp = first_forecast['main']['temp']
            forecast_text += f"- Hi·ªán t·∫°i: {desc}, {temp}¬∞C\n"
        return forecast_text
    except Exception as e:
        return f"‚ö†Ô∏è L·ªói khi l·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt: {e}"

# -------------------------
# PIXABAY IMAGE FUNCTIONS
# -------------------------
def get_pixabay_image(query, per_page=3):
    if not PIXABAY_API_KEY:
        return None
    try:
        url = "https://pixabay.com/api/"
        params = {
            "key": PIXABAY_API_KEY,
            "q": query,
            "image_type": "photo",
            "orientation": "horizontal",
            "safesearch": "true",
            "per_page": per_page,
        }
        res = requests.get(url, params=params, timeout=8)
        data = res.json()
        if data.get("hits"):
            return data["hits"][0].get("largeImageURL") or data["hits"][0].get("webformatURL")
        return None
    except Exception:
        return None

def get_city_image(city):
    if not city:
        return None
    queries = [
        f"{city} Vietnam landscape",
        f"{city} Vietnam city",
        f"{city} Vietnam travel",
        "Vietnam travel landscape"
    ]
    for q in queries:
        img = get_pixabay_image(q)
        if img:
            return img
    return "https://via.placeholder.com/1200x800?text=No+Image"

def get_food_images(food_list):
    images = []
    for food in food_list[:5]:
        query = f"{food} Vietnam food"
        img_url = get_pixabay_image(query)
        if not img_url:
            img_url = "https://via.placeholder.com/400x300?text=No+Image"
        images.append({"name": food, "image": img_url})
    return images

# -------------------------
# RESTAURANTS HYBRID (Google Places + CSV fallback)
# -------------------------
def get_restaurants_google(city, api_key, limit=5):
    try:
        query = f"nh√† h√†ng t·∫°i {city}, Vi·ªát Nam"
        url = "https://maps.googleapis.com/maps/api/place/textsearch/json"
        params = {"query": query, "key": api_key, "language": "vi"}
        res = requests.get(url, params=params, timeout=10).json()
        if "error_message" in res:
            return [{"error": res["error_message"]}]
        results = []
        for r in res.get("results", [])[:limit]:
            results.append({
                "name": r.get("name"),
                "rating": r.get("rating", "N/A"),
                "address": r.get("formatted_address", ""),
                "maps_url": f"https://www.google.com/maps/place/?q=place_id:{r.get('place_id')}"
            })
        return results
    except Exception as e:
        return [{"error": str(e)}]

def get_local_restaurants(city, limit=5):
    try:
        df = pd.read_csv("data/restaurants_vn.csv")
        df_city = df[df["city"].str.lower().str.contains(str(city).lower(), na=False)]
        if df_city.empty:
            return []
        return df_city.head(limit).to_dict("records")
    except Exception:
        return []

def get_restaurants(city, limit=5):
    if not city:
        return []
    if GOOGLE_PLACES_KEY:
        data = get_restaurants_google(city, GOOGLE_PLACES_KEY, limit)
        if data and not data[0].get("error"):
            return data
    return get_local_restaurants(city, limit)

# -------------------------
# FOOD AI ASSISTANT (CSV + GPT fallback)
# -------------------------
def re_split_foods(s):
    for sep in [",", "|", ";"]:
        if sep in s:
            return [p.strip() for p in s.split(sep) if p.strip()]
    return [s.strip()]

def get_local_foods(city):
    try:
        df = pd.read_csv("data/vietnam_foods.csv", dtype=str)
        mask = df["city"].str.lower().str.contains(str(city).lower(), na=False)
        row = df[mask]
        if not row.empty:
            row0 = row.iloc[0]
            if "foods" in row0.index:
                foods_cell = row0["foods"]
                if pd.notna(foods_cell):
                    return re_split_foods(foods_cell)
            else:
                vals = row0.dropna().tolist()
                if len(vals) > 1:
                    return [v for v in vals[1:]]
    except Exception:
        pass
    return []

def get_foods_via_gpt(city, max_items=5):
    if not client:
        return []
    try:
        prompt = (
            f"You are an expert on Vietnamese cuisine.\n"
            f"List up to {max_items} iconic or must-try dishes from the city/region '{city}'.\n"
            "Return only a comma-separated list of dish names (no extra text)."
        )
        response = client.chat.completions.create(
            model=DEPLOYMENT_NAME,
            messages=[{"role":"system","content":prompt}],
            max_tokens=150,
            temperature=0.5
        )
        text = response.choices[0].message.content.strip()
        items = [t.strip() for t in text.split(",") if t.strip()]
        return items[:max_items]
    except Exception:
        return []

def get_local_foods_with_fallback(city):
    foods = get_local_foods(city)
    if not foods:
        foods = get_foods_via_gpt(city)
    return foods

# -------------------------
# SUGGESTIONS / COST / PHOTOSPOTS
# -------------------------
def estimate_cost(city, days=3, people=1, style="trung b√¨nh"):
    mapping = {"ti·∫øt ki·ªám": 400000, "trung b√¨nh": 800000, "cao c·∫•p": 2000000}
    per_day = mapping.get(style, 800000)
    total = per_day * days * people
    return f"üí∏ Chi ph√≠ ∆∞·ªõc t√≠nh: kho·∫£ng {total:,} VNƒê cho {people} ng∆∞·ªùi, {days} ng√†y."

def suggest_local_food(city):
    return f"üçú G√µ 'ƒê·∫∑c s·∫£n {city}' ƒë·ªÉ nh·∫≠n danh s√°ch m√≥n ƒÉn n·ªïi b·∫≠t."

def suggest_events(city):
    return f"üéâ S·ª± ki·ªán ·ªü {city}: l·ªÖ h·ªôi ƒë·ªãa ph∆∞∆°ng, ch·ª£ ƒë√™m, h·ªôi ch·ª£ ·∫©m th·ª±c (tu·ª≥ m√πa)."

def suggest_photospots(city):
    return f"üì∏ G·ª£i √Ω check-in: trung t√¢m l·ªãch s·ª≠, b·ªù s√¥ng/bi·ªÉn, qu√°n c√† ph√™ c√≥ view ƒë·∫πp."

# -------------------------
# BILINGUAL CITY & DATE EXTRACTION
# -------------------------
def extract_city_and_dates(user_text):
    if not client:
        return None, None, None
    try:
        prompt = f"""
You are a multilingual travel information extractor.
Extract 'city','start_date','end_date' (YYYY-MM-DD). 
If only one date is provided, set both to that date.
If no date is mentioned, set both start_date and end_date to null.
Return JSON only.
Message: "{user_text}"
"""
        response = client.chat.completions.create(
            model=DEPLOYMENT_NAME,
            messages=[{"role":"system","content":prompt}],
            max_tokens=300,
            temperature=0
        )
        content = response.choices[0].message.content.strip()
        start = content.find('{')
        end = content.rfind('}')
        if start == -1 or end == -1:
            return None, None, None
        data = json.loads(content[start:end+1])
        city = data.get("city")
        s = data.get("start_date")
        e = data.get("end_date")
        
        # TH√äM: Ki·ªÉm tra n·∫øu ng√†y l√† null ho·∫∑c r·ªóng
        def _parse(d):
            if not d or d.lower() == 'null' or d == '':
                return None
            try:
                dt = datetime.strptime(d, "%Y-%m-%d")
                return dt
            except ValueError:
                return None
                
        start_dt = _parse(s)
        end_dt = _parse(e)
        
        # TH√äM: Ki·ªÉm tra ng√†y h·ª£p l·ªá
        today = datetime.now().date()
        if start_dt and start_dt.date() < today:
            # N·∫øu ng√†y trong qu√° kh·ª©, b·ªè qua v√† coi nh∆∞ kh√¥ng c√≥ ng√†y
            start_dt = None
            
        if end_dt and end_dt.date() < today:
            end_dt = None
            
        if start_dt and not end_dt:
            end_dt = start_dt
            
        return city, start_dt, end_dt
    except Exception:
        return None, None, None

# -------------------------
# RAG / Chroma helper functions
# -------------------------
def rag_query_top_k(user_text, k=5):
    """
    L·∫•y top-k ƒëo·∫°n vƒÉn t·ª´ collection vietnam_travel b·∫±ng embedding.
    Tr·∫£ v·ªÅ list dict v√† context string.
    """
    if chroma_travel_col is None or client is None:
        return [], ""
    emb = get_embedding_local(user_text)  # ƒê√É THAY ƒê·ªîI: d√πng embedding local
    if emb is None:
        return [], ""
    try:
        res = chroma_travel_col.query(query_embeddings=[emb], n_results=k, include=["documents","metadatas","distances"])
        docs = []
        
        # FIX: Properly handle ChromaDB response structure
        docs_texts = res.get("documents", [[]])
        if docs_texts and isinstance(docs_texts, list):
            docs_texts = docs_texts[0] if docs_texts and isinstance(docs_texts[0], list) else docs_texts
            
        metadatas = res.get("metadatas", [[]])
        if metadatas and isinstance(metadatas, list):
            metadatas = metadatas[0] if metadatas and isinstance(metadatas[0], list) else metadatas
            
        ids = res.get("ids", [[]])
        if ids and isinstance(ids, list):
            ids = ids[0] if ids and isinstance(ids[0], list) else ids
            
        distances = res.get("distances", [[]])
        if distances and isinstance(distances, list):
            distances = distances[0] if distances and isinstance(distances[0], list) else distances

        # Ensure all are lists and have same length
        docs_texts = docs_texts or []
        metadatas = metadatas or [{}] * len(docs_texts)
        ids = ids or [f"doc_{i}" for i in range(len(docs_texts))]
        distances = distances or [None] * len(docs_texts)

        for i, txt in enumerate(docs_texts):
            meta = metadatas[i] if i < len(metadatas) else {}
            doc_id = ids[i] if i < len(ids) else f"doc_{i}"
            distance = distances[i] if i < len(distances) else None
            
            docs.append({
                "id": doc_id,
                "text": txt,
                "metadata": meta,
                "distance": distance
            })
            
        context_parts = []
        for d in docs:
            src = d["metadata"].get("source", "") if isinstance(d.get("metadata"), dict) else ""
            context_parts.append(f"[src:{d['id']}{('|' + src) if src else ''}] {d['text'][:1200]}")
        context = "\n\n".join(context_parts)
        st.session_state["last_rag_docs"] = docs  # l∆∞u ngu·ªìn v√†o session
        return docs, context
    except Exception as e:
        print(f"[WARN] chroma query error: {e}")
        return [], ""

def add_to_memory_collection(text, role="user", city=None, extra_meta=None):
    """
    L∆∞u embedding + text v√†o collection chat_memory.
    """
    if chroma_memory_col is None or client is None:
        return
    try:
        emb = get_embedding_local(text)  # ƒê√É THAY ƒê·ªîI: d√πng embedding local
        doc_id = f"mem_{int(time.time()*1000)}_{uuid.uuid4().hex[:8]}"
        meta = {"role": role, "city": city or "", "timestamp": datetime.utcnow().isoformat()}
        if extra_meta and isinstance(extra_meta, dict):
            meta.update(extra_meta)
        # Some chroma versions accept embeddings param, others compute embedding on add
        try:
            chroma_memory_col.add(documents=[text], metadatas=[meta], ids=[doc_id], embeddings=[emb])
        except TypeError:
            # fallback without embeddings param
            chroma_memory_col.add(documents=[text], metadatas=[meta], ids=[doc_id])
    except Exception as e:
        print(f"[WARN] add to memory failed: {e}")

def recall_recent_memories(user_text, k=5):
    """
    Truy v·∫•n chat_memory b·∫±ng embedding user_text ƒë·ªÉ l·∫•y c√°c ƒëo·∫°n h·ªôi tho·∫°i g·∫ßn nh·∫•t.
    """
    if chroma_memory_col is None or client is None:
        return []
    emb = get_embedding_local(user_text)  # ƒê√É THAY ƒê·ªîI: d√πng embedding local
    if emb is None:
        return []
    try:
        res = chroma_memory_col.query(query_embeddings=[emb], n_results=k, include=["documents","metadatas","distances"])
        items = []
        
        # FIX: Properly handle ChromaDB response structure
        docs_texts = res.get("documents", [[]])
        if docs_texts and isinstance(docs_texts, list):
            docs_texts = docs_texts[0] if docs_texts and isinstance(docs_texts[0], list) else docs_texts
        
        metadatas = res.get("metadatas", [[]])
        if metadatas and isinstance(metadatas, list):
            metadatas = metadatas[0] if metadatas and isinstance(metadatas[0], list) else metadatas
            
        ids = res.get("ids", [[]])
        if ids and isinstance(ids, list):
            ids = ids[0] if ids and isinstance(ids[0], list) else ids
            
        distances = res.get("distances", [[]])
        if distances and isinstance(distances, list):
            distances = distances[0] if distances and isinstance(distances[0], list) else distances

        # Ensure all are lists and have same length
        docs_texts = docs_texts or []
        metadatas = metadatas or [{}] * len(docs_texts)
        ids = ids or [f"mem_{i}" for i in range(len(docs_texts))]
        distances = distances or [None] * len(docs_texts)

        for i, t in enumerate(docs_texts):
            meta = metadatas[i] if i < len(metadatas) else {}
            item_id = ids[i] if i < len(ids) else f"mem_{i}"
            distance = distances[i] if i < len(distances) else None
            
            items.append({
                "id": item_id, 
                "text": t, 
                "meta": meta, 
                "distance": distance
            })
        return items
    except Exception as e:
        print(f"[WARN] recall error: {e}")
        return []

def get_intent_via_chroma(user_text, threshold=0.2):
    """
    Truy v·∫•n intent_bank t√¨m intent g·∫ßn nh·∫•t. N·∫øu distance < threshold => tr·∫£ v·ªÅ intent id.
    """
    if chroma_intent_col is None or client is None:
        return None
    emb = get_embedding_local(user_text)  # ƒê√É THAY ƒê·ªîI: d√πng embedding local
    if emb is None:
        return None
    try:
        res = chroma_intent_col.query(query_embeddings=[emb], n_results=1, include=["metadatas","distances"])
        
        # FIX: Properly handle ChromaDB response structure
        distances = res.get("distances", [[]])
        if distances and isinstance(distances, list):
            distances = distances[0] if distances and isinstance(distances[0], list) else distances
            
        metadatas = res.get("metadatas", [[]])
        if metadatas and isinstance(metadatas, list):
            metadatas = metadatas[0] if metadatas and isinstance(metadatas[0], list) else metadatas

        if distances and len(distances) > 0 and distances[0] is not None and distances[0] < threshold:
            meta = metadatas[0] if metadatas and len(metadatas) > 0 else {}
            return meta.get("intent") if isinstance(meta, dict) else None
    except Exception as e:
        print(f"[WARN] intent chroma error: {e}")
    return None

def recommend_similar_trips(city, k=3):
    """
    T√¨m trong chat_memory c√°c trips t∆∞∆°ng t·ª± d·ª±a tr√™n city (ho·∫∑c m√¥ t·∫£).
    """
    if chroma_memory_col is None:
        return []
    emb = get_embedding_local(city)  # ƒê√É THAY ƒê·ªîI: d√πng embedding local
    if emb is None:
        return []
    try:
        res = chroma_memory_col.query(query_embeddings=[emb], n_results=10, include=["documents","metadatas","distances"])
        
        # FIX: Properly handle ChromaDB response structure
        docs_texts = res.get("documents", [[]])
        if docs_texts and isinstance(docs_texts, list):
            docs_texts = docs_texts[0] if docs_texts and isinstance(docs_texts[0], list) else docs_texts
            
        metadatas = res.get("metadatas", [[]])
        if metadatas and isinstance(metadatas, list):
            metadatas = metadatas[0] if metadatas and isinstance(metadatas[0], list) else metadatas
            
        ids = res.get("ids", [[]])
        if ids and isinstance(ids, list):
            ids = ids[0] if ids and isinstance(ids[0], list) else ids

        recommendations = []
        for i, m in enumerate(metadatas):
            rec_city = m.get("city") if isinstance(m, dict) else None
            if rec_city and rec_city.lower() != city.lower() and rec_city not in [r.get("city") for r in recommendations]:
                doc = docs_texts[i] if i < len(docs_texts) else ""
                rec_id = ids[i] if i < len(ids) else None
                recommendations.append({"city": rec_city, "meta": m, "doc": doc, "id": rec_id})
            if len(recommendations) >= k:
                break
        return recommendations
    except Exception as e:
        print(f"[WARN] recommend error: {e}")
        return []

# preload intents samples
def preload_intents():
    if chroma_intent_col is None or client is None:
        return
    try:
        samples = [
            ("Th·ªùi ti·∫øt ·ªü {city} tu·∫ßn t·ªõi?", {"intent":"weather_query"}),
            ("L·ªãch tr√¨nh 3 ng√†y ·ªü {city}", {"intent":"itinerary_request"}),
            ("ƒê·∫∑c s·∫£n {city}", {"intent":"food_query"}),
            ("G·ª£i √Ω nh√† h√†ng ·ªü {city}", {"intent":"restaurant_query"})
        ]
        docs = []
        metas = []
        ids = []
        for i, (t, meta) in enumerate(samples):
            docs.append(t)
            metas.append(meta)
            ids.append(f"intent_sample_{i}")
        chroma_intent_col.add(documents=docs, metadatas=metas, ids=ids)
    except Exception as e:
        print(f"[WARN] preload intents: {e}")

try:
    preload_intents()
except Exception:
    pass

# -------------------------
# HERO / HEADER SECTION
# -------------------------
def render_hero_section(default_city_hint="H·ªôi An, ƒê√† N·∫µng, H√† N·ªôi..."):
    with st.form(key='hero_search_form', clear_on_submit=False):
        cols = st.columns([3,2,1,1])
        dest = cols[0].text_input("ƒêi·ªÉm ƒë·∫øn", placeholder=default_city_hint)
        dates = cols[1].date_input("Ng√†y (b·∫Øt ƒë·∫ßu / k·∫øt th√∫c)", [])
        people = cols[2].selectbox("Ng∆∞·ªùi", [1,2,3,4,5,6], index=0)
        style = cols[3].selectbox("M·ª©c chi", ["trung b√¨nh", "ti·∫øt ki·ªám", "cao c·∫•p"], index=0)
        submitted = st.form_submit_button("G·ª£i √Ω nhanh", use_container_width=True)
        if submitted:
            if len(dates) == 2:
                s = dates[0].strftime("%Y-%m-%d")
                e = dates[1].strftime("%Y-%m-%d")
                q = f"L·ªãch tr√¨nh { ( (dates[1]-dates[0]).days +1 ) } ng√†y ·ªü {dest} t·ª´ {s} ƒë·∫øn {e}"
            elif len(dates) == 1:
                s = dates[0].strftime("%Y-%m-%d")
                q = f"L·ªãch tr√¨nh 1 ng√†y ·ªü {dest} v√†o {s}"
            else:
                q = f"L·ªãch tr√¨nh 3 ng√†y ·ªü {dest}"
            q += f" ‚Ä¢ ng∆∞·ªùi: {people} ‚Ä¢ m·ª©c: {style}"
            st.session_state.user_input = q
            st.rerun()
    # # TH√äM D√íNG N√ÄY SAU st.rerun() ƒë·ªÉ clear form:
    # st.session_state.hero_search_form = False
# -------------------------
# VOICE HELPERS
# -------------------------
def detect_audio_type_header(b):
    if len(b) < 12:
        return None
    if b[0:4] == b'RIFF' and b[8:12] == b'WAVE':
        return 'wav'
    if b[0:4] == b'fLaC':
        return 'flac'
    if b[0:4] == b'OggS':
        return 'ogg'
    if b[0:4] == b'\x1A\x45\xDF\xA3':
        return 'webm'
    if b[0:3] == b'ID3' or b[0] == 0xFF:
        return 'mp3'
    return None

def write_temp_file_and_convert_to_wav(audio_bytes):
    header = audio_bytes[:64]
    atype = detect_audio_type_header(header)
    ext_map = {'wav': '.wav', 'ogg': '.ogg', 'webm': '.webm', 'mp3': '.mp3', 'flac': '.flac'}
    ext = ext_map.get(atype, '.webm')
    tmp_dir = tempfile.mkdtemp()
    src_path = os.path.join(tmp_dir, "input" + ext)
    wav_path = os.path.join(tmp_dir, "converted.wav")
    with open(src_path, "wb") as f:
        f.write(audio_bytes)
    if atype == 'wav':
        return src_path
    try:
        audio = AudioSegment.from_file(src_path)
        audio = audio.set_frame_rate(16000).set_channels(1)
        audio.export(wav_path, format="wav")
        return wav_path
    except Exception as e:
        try:
            cmd = ["ffmpeg", "-y", "-i", src_path, "-ar", "16000", "-ac", "1", wav_path]
            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            return wav_path
        except Exception as e2:
            raise RuntimeError(f"Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi audio sang WAV: {e} | {e2}")

# -------------------------
# TOPIC CLASSIFIER (OpenAI) - d√πng ƒë·ªÉ ki·ªÉm tra n·∫øu b·∫°n mu·ªën reject non-travel
# -------------------------
def is_travel_related_via_gpt(user_text):
    """
    D√πng OpenAI ƒë·ªÉ x√°c ƒë·ªãnh xem c√¢u h·ªèi c√≥ li√™n quan ƒë·∫øn du l·ªãch kh√¥ng.
    Tr·∫£ v·ªÅ True n·∫øu li√™n quan, False n·∫øu kh√¥ng.
    """
    if not client:
        return True  # n·∫øu kh√¥ng c√≥ API key th√¨ cho qua lu√¥n

    try:
        prompt = f"""
B·∫°n l√† b·ªô ph√¢n lo·∫°i ch·ªß ƒë·ªÅ th√¥ng minh.
H√£y x√°c ƒë·ªãnh xem c√¢u sau c√≥ li√™n quan ƒë·∫øn lƒ©nh v·ª±c *du l·ªãch Vi·ªát Nam* hay kh√¥ng.

C√°c ch·ªß ƒë·ªÅ ƒë∆∞·ª£c coi l√† li√™n quan bao g·ªìm:
- ƒë·ªãa ƒëi·ªÉm, th√†nh ph·ªë, t·ªânh, danh lam th·∫Øng c·∫£nh
- th·ªùi ti·∫øt, kh√≠ h·∫≠u
- l·ªãch tr√¨nh du l·ªãch, tour, chi ph√≠, g·ª£i √Ω ƒëi·ªÉm ƒë·∫øn
- m√≥n ƒÉn ƒë·ªãa ph∆∞∆°ng, ƒë·∫∑c s·∫£n, nh√† h√†ng
- kh√°ch s·∫°n, homestay, resort
- s·ª± ki·ªán, l·ªÖ h·ªôi, vƒÉn ho√° v√πng mi·ªÅn

N·∫øu KH√îNG thu·ªôc nh·ªØng ch·ªß ƒë·ªÅ tr√™n (v√≠ d·ª•: l·∫≠p tr√¨nh, t√†i ch√≠nh, th·ªÉ thao, h·ªçc t·∫≠p...), h√£y tr·∫£ v·ªÅ JSON:
{{"related": false}}

N·∫øu C√ì li√™n quan, tr·∫£ v·ªÅ JSON:
{{"related": true}}

C√¢u ng∆∞·ªùi d√πng: "{user_text}"
"""
        response = client.chat.completions.create(
            model=DEPLOYMENT_NAME,
            messages=[{"role": "system", "content": prompt}],
            temperature=0,
            max_tokens=30,
        )
        text = response.choices[0].message.content.strip().lower()
        if '"related": true' in text:
            return True
        if '"related": false' in text:
            return False
    except Exception as e:
        print(f"[WARN] L·ªói ph√¢n lo·∫°i ch·ªß ƒë·ªÅ: {e}")
    return True  # fallback

# -------------------------
# STREAMLIT UI LAYOUT
# -------------------------
render_hero_section()
main_tab, analytics_tab = st.tabs(["üí¨ Tr√≤ chuy·ªán v·ªõi [M√¢y lang thang]", "üìä Th·ªëng k√™ truy v·∫•n"])

with st.sidebar:
    st.markdown("<div class='logo-title'><img src='https://img.icons8.com/emoji/48/000000/cloud-emoji.png'/> <h2>M√¢y Lang Thang</h2></div>", unsafe_allow_html=True)
    st.header("‚öôÔ∏èC√†i ƒë·∫∑t")
    info_options = st.multiselect("Hi·ªÉn th·ªã th√¥ng tin",
                                  ["Weather", "Food", "Map", "Photos", "Cost", "Events"],
                                  default=["Weather", "Map","Food", "Photos"])
    st.markdown("---")
    st.subheader("üéôÔ∏è Voice")
    enable_voice = st.checkbox("B·∫≠t nh·∫≠p li·ªáu b·∫±ng gi·ªçng n√≥i", value=True)
    asr_lang = st.selectbox("Ng√¥n ng·ªØ nh·∫≠n d·∫°ng", ["vi-VN"], index=0)
    tts_enable = st.checkbox("üîä ƒê·ªçc to ph·∫£n h·ªìi", value=False)
    tts_lang = st.selectbox("Ng√¥n ng·ªØ TTS", ["vi"], index=0)
    st.caption("Y√™u c·∫ßu: ffmpeg + internet cho gTTS.")
    # st.markdown("---")
    # st.write("üó∫Ô∏èCh·ªçn m·ª©c zoom b·∫£n ƒë·ªì:")
    st.subheader("üó∫Ô∏è Ch·ªçn m·ª©c zoom b·∫£n ƒë·ªì:")
    map_zoom = st.slider("Zoom (4 = xa, 15 = g·∫ßn)", 4, 15, 8)
    # st.markdown("---")
    # st.subheader("‚öôÔ∏è Qu·∫£n l√Ω d·ªØ li·ªáu")
    # st.markdown("---")
    # N√∫t seed d·ªØ li·ªáu th·ªß c√¥ng
    if st.button("üîÑ Seed d·ªØ li·ªáu du l·ªãch", use_container_width=True):
        try:
            seed_vietnam_travel_from_csv("data/vietnam_travel_docs.csv")
            st.success("‚úÖ ƒê√£ seed d·ªØ li·ªáu th√†nh c√¥ng t·ª´ [data/vietnam_travel_docs.csv]!")
        except Exception as e:
            st.error(f"‚ùå L·ªói khi seed d·ªØ li·ªáu: {e}")

    # T·ª± ƒë·ªông seed d·ªØ li·ªáu n·∫øu collection tr·ªëng
    try:
        if chroma_travel_col and chroma_travel_col.count() == 0:
            if seed_vietnam_travel_from_csv("data/vietnam_travel_docs.csv"):
                st.sidebar.success("‚úÖ ƒê√£ t·ª± ƒë·ªông seed d·ªØ li·ªáu du l·ªãch")
            else:
                st.sidebar.warning("‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu du l·ªãch. Vui l√≤ng seed th·ªß c√¥ng.")
    except Exception as e:
        st.sidebar.warning(f"‚ö†Ô∏è Ch∆∞a seed ƒë∆∞·ª£c d·ªØ li·ªáu: {e}")
    st.markdown("---")
    def status_card(title, ok=True):
        cls = "status-ok" if ok else "status-bad"
        icon = "‚úÖ" if ok else "‚ö†Ô∏è"
        st.markdown(f"<div class='{cls}'>{icon} {title}</div>", unsafe_allow_html=True)
    status_card("OpenWeatherMap", bool(OPENWEATHERMAP_API_KEY))
    # status_card("Google Places", bool(GOOGLE_PLACES_KEY))
    status_card("Pixabay", bool(PIXABAY_API_KEY))
    
    # Th√™m tr·∫°ng th√°i ChromaDB
    chroma_status = chroma_client is not None and chroma_travel_col is not None
    status_card("ChromaDB RAG", chroma_status)
    
    # Th√™m tr·∫°ng th√°i Embedding Model
    embedding_status = embedding_model is not None
    status_card("Embedding Model", embedding_status)
    st.caption("üçú Food AI: CSV local d·ªØ li·ªáu + GPT fallback")
    st.markdown("Version: v1.3 + Voice + RAG + Local Embedding")
    st.markdown("By [M√¢y Lang Thang](https://#) ‚ù§Ô∏è")
# initialize session messages
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": system_prompt}]

with main_tab:
    today = datetime.now().date()
    if "quicksearch" in st.session_state:
        qs = st.session_state.quicksearch
        city_qs = qs["city"]; start_qs = qs["start"]; end_qs = qs["end"]
        people_qs = qs["people"]; style_qs = qs["style"]
        st.markdown(f"### ‚úàÔ∏è G·ª£i √Ω cho chuy·∫øn ƒëi {city_qs} ({start_qs} ‚Äì {end_qs})")
        weather_qs = get_weather_forecast(city_qs, start_qs, end_qs)
        cost_qs = estimate_cost(city_qs, (end_qs - start_qs).days + 1, people_qs, style_qs)
        colA, colB = st.columns(2)
        with colA:
            st.markdown(f"**{weather_qs}**")
            st.markdown(f"**{cost_qs}**")
        with colB:
            img = get_city_image(city_qs)
            if img:
                st.image(img, caption=f"üèûÔ∏è {city_qs}", use_container_width=True)
            lat, lon, addr = geocode_city(city_qs)
            if lat and lon:
                show_map(lat, lon, zoom=map_zoom, title=addr or city_qs)
        st.markdown("---")

    # === VOICE INPUT BAR ===
    voice_text = None
    if enable_voice:
        audio = mic_recorder(
            start_prompt="üéôÔ∏è [Chat voice] N√≥i ƒë·ªÉ nh·∫≠p c√¢u h·ªèi",
            stop_prompt="‚úãD·ª´ng nh·∫≠n di·ªán gi·ªçng n√≥i",
            just_once=True,
            key="rec_chat"
        )
        if audio:
            st.info("ƒê√£ nh·∫≠n d·ªØ li·ªáu √¢m thanh, ƒëang x·ª≠ l√Ω...")
            try:
                wav_file = write_temp_file_and_convert_to_wav(audio["bytes"])
            except Exception as e:
                wav_file = None
                st.error(f"Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi audio: {e}")
            if wav_file:
                r = sr.Recognizer()
                try:
                    with sr.AudioFile(wav_file) as source:
                        audio_data = r.record(source)
                        voice_text = r.recognize_google(audio_data, language=asr_lang)
                        st.success(f"üó£Ô∏è B·∫°n n√≥i: {voice_text}")
                        st.session_state.user_input = voice_text
                        st.rerun()
                except sr.UnknownValueError:
                    st.error("Kh√¥ng th·ªÉ nh·∫≠n di·ªán gi·ªçng n√≥i (UnknownValueError).")
                except Exception as e:
                    st.error(f"L·ªói nh·∫≠n di·ªán: {e}")

    # --- Hi·ªÉn th·ªã l·∫°i to√†n b·ªô l·ªãch s·ª≠ c≈© ---
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            with st.chat_message("user", avatar="üß≠"):
                st.markdown(f"<div class='user-message'>{msg['content']}</div>", unsafe_allow_html=True)
        elif msg["role"] == "assistant":
            with st.chat_message("assistant", avatar="ü§ñ"):
                st.markdown(f"<div class='assistant-bubble'>{msg['content']}</div>", unsafe_allow_html=True)

    # Chat input (g√µ ph√≠m)
    user_input = st.chat_input("M·ªùi b·∫°n ƒë·∫∑t c√¢u h·ªèi:")
    # X√≥a state sau khi ƒë√£ s·ª≠ d·ª•ng ƒë·ªÉ tr√°nh l·∫∑p l·∫°i
    if "user_input" in st.session_state and st.session_state.user_input:
        user_input = st.session_state.user_input
        # QUAN TR·ªåNG: X√≥a state ngay sau khi s·ª≠ d·ª•ng
        del st.session_state.user_input

    if user_input:
        with st.chat_message("user", avatar="üß≠"):
            st.markdown(f"<div class='user-message'>{user_input}</div>", unsafe_allow_html=True)
        st.session_state.messages.append({"role": "user", "content": user_input})

        # Optional: reject non-travel topics via GPT classifier
        try:
            if not is_travel_related_via_gpt(user_input):
                msg = "Xin l·ªói üòÖ, t√¥i ch·ªâ h·ªó tr·ª£ c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn **du l·ªãch Vi·ªát Nam**, nh∆∞ th·ªùi ti·∫øt, ƒë·ªãa ƒëi·ªÉm, m√≥n ƒÉn, l·ªãch tr√¨nh..."
                with st.chat_message("assistant", avatar="ü§ñ"):
                    st.markdown(msg)
                st.session_state.messages.append({"role": "assistant", "content": msg})
                # add to memory (optional)
                try:
                    add_to_memory_collection(user_input, role="user")
                    add_to_memory_collection(msg, role="assistant")
                except Exception:
                    pass
                st.stop()
        except Exception:
            # n·∫øu classifier l·ªói th√¨ ti·∫øp t·ª•c b√¨nh th∆∞·ªùng
            pass

        city_guess, start_date, end_date = extract_city_and_dates(user_input)

        # S·ª¨A: X·ª≠ l√Ω khi kh√¥ng c√≥ ng√†y c·ª• th·ªÉ - l·∫•y ng√†y hi·ªán t·∫°i
        today = datetime.now().date()
        if start_date is None:
            start_date = datetime.combine(today, datetime.min.time())
        if end_date is None:
            end_date = datetime.combine(today, datetime.min.time())

        # ƒê·∫£m b·∫£o end_date kh√¥ng nh·ªè h∆°n start_date
        if end_date < start_date:
            end_date = start_date

        days = extract_days_from_text(user_input, start_date, end_date)
        
        # Reset c√°c bi·∫øn tracking
        rag_used = False
        sources_count = 0
        intent_used = None
        memory_used = False

        # S·ª¨A: Ki·ªÉm tra c·∫£ start_date v√† ƒë·∫£m b·∫£o n√≥ kh√¥ng ph·∫£i l√† ng√†y hi·ªán t·∫°i (tr√°nh c·∫£nh b√°o kh√¥ng c·∫ßn thi·∫øt)
        if start_date and start_date.date() != datetime.now().date():
            today = datetime.now().date()
            max_forecast_date = today + timedelta(days=5)
            if start_date.date() > max_forecast_date:
                st.warning(f"‚ö†Ô∏è L∆∞u √Ω: OpenWeather ch·ªâ cung c·∫•p d·ª± b√°o ~5 ng√†y. B·∫°n y√™u c·∫ßu b·∫Øt ƒë·∫ßu {start_date.strftime('%d/%m/%Y')}.")

        blocks = []
        if city_guess and "Weather" in info_options:
            blocks.append(get_weather_forecast(city_guess, start_date, end_date, user_input))
        if city_guess and "Cost" in info_options:
            blocks.append(estimate_cost(city_guess, days=days))
        if city_guess and "Events" in info_options:
            blocks.append(suggest_events(city_guess))

        for b in blocks:
            with st.chat_message("assistant", avatar="ü§ñ"):
                if isinstance(b, str):
                    st.markdown(b.replace("\\n", "\n"))
                else:
                    st.write(b)

        with st.spinner("‚è≥ ƒêang so·∫°n ph·∫£n h·ªìi..."):
            try:
                progress_text = "AI ƒëang ph√¢n t√≠ch d·ªØ li·ªáu du l·ªãch..."
                progress_bar = st.progress(0, text=progress_text)
                for percent_complete in range(0, 101, 20):
                    time.sleep(0.08)
                    progress_bar.progress(percent_complete, text=progress_text)
                progress_bar.empty()

                assistant_text = ""
                if client:
                    # --- RAG + Intent + Memory enhanced generation ---
                    try:
                        detected_intent = get_intent_via_chroma(user_input, threshold=0.18)
                        if detected_intent:
                            intent_used = detected_intent
                            if detected_intent == "weather_query" and city_guess:
                                assistant_text = get_weather_forecast(city_guess, start_date, end_date, user_input)
                                assistant_text += f"\n\n( Ngu·ªìn: OpenWeatherMap )"
                            elif detected_intent == "food_query" and city_guess:
                                foods = get_local_foods_with_fallback(city_guess)
                                assistant_text = "ƒê·∫∑c s·∫£n n·ªïi b·∫≠t:\n" + "\n".join([f"- {f}" for f in foods]) if foods else "Kh√¥ng t√¨m th·∫•y ƒë·∫∑c s·∫£n trong DB."
                            elif detected_intent == "itinerary_request" and city_guess:
                                days_local = extract_days_from_text(user_input, start_date, end_date)
                                assistant_text = f"L·ªãch tr√¨nh g·ª£i √Ω cho {city_guess}, {days_local} ng√†y:\n1) Ng√†y 1: ...\n2) Ng√†y 2: ...\n3) Ng√†y 3: ..."
                            else:
                                # Unknown or not handled intent -> fallback to full generation
                                detected_intent = None
                                intent_used = None
                        if not detected_intent:
                            docs, rag_context = rag_query_top_k(user_input, k=5)
                            sources_count = len(docs)
                            recent_mem = recall_recent_memories(user_input, k=3)
                            memory_used = len(recent_mem) > 0
                            recall_text = ""
                            if recent_mem:
                                recall_parts = []
                                for m in recent_mem:
                                    ts = m.get("meta", {}).get("timestamp", "")
                                    role = m.get("meta", {}).get("role", "")
                                    recall_parts.append(f"[mem:{m.get('id')}] ({role} {ts}) {m.get('text')[:400]}")
                                recall_text = "\n\n".join(recall_parts)

                            augmentation = "\n\n--- Th√¥ng tin tham kh·∫£o n·ªôi b·ªô (tr√≠ch d·∫´n): ---\n"
                            if rag_context:
                                rag_used = True
                                augmentation += rag_context + "\n\n"
                            if recall_text:
                                augmentation += "\n--- Nh·ªõ g·∫ßn ƒë√¢y ---\n" + recall_text + "\n\n"
                            augmentation += "--- Khi tr·∫£ l·ªùi, n·∫øu d√πng th√¥ng tin t·ª´ ph·∫ßn tr√™n h√£y ƒë√°nh d·∫•u ngu·ªìn nh∆∞ [src:ID] ho·∫∑c [mem:ID]. ---\n"

                            temp_messages = [{"role":"system", "content": system_prompt + "\n\n" + augmentation}]
                            temp_messages.extend(st.session_state.messages[-12:])  # keep last 12 msgs
                            response = client.chat.completions.create(
                                model=DEPLOYMENT_NAME,
                                messages=temp_messages,
                                max_tokens=900,
                                temperature=0.7
                            )
                            assistant_text = response.choices[0].message.content.strip()

                        # Save to memory
                        try:
                            add_to_memory_collection(user_input, role="user", city=city_guess)
                            add_to_memory_collection(assistant_text, role="assistant", city=city_guess)
                        except Exception:
                            pass

                    except Exception as e:
                        assistant_text = f"‚ö†Ô∏è L·ªói khi t·∫°o ph·∫£n h·ªìi: {e}"
                else:
                    assistant_text = f"Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p b·∫°n v·ªõi th√¥ng tin v·ªÅ {city_guess or 'ƒë·ªãa ƒëi·ªÉm'} ‚Äî th·ª≠ h·ªèi 'Th·ªùi ti·∫øt', 'ƒê·∫∑c s·∫£n', ho·∫∑c 'L·ªãch tr√¨nh 3 ng√†y'."

                if not assistant_text.endswith(("üå§Ô∏è‚ù§Ô∏è", "üòä", "üå∏", "üå¥", "‚ú®")):
                    assistant_text += "\n\nCh√∫c b·∫°n c√≥ chuy·∫øn ƒëi vui v·∫ª üå§Ô∏è‚ù§Ô∏è"

                st.session_state.messages.append({"role": "assistant", "content": assistant_text})

                with st.chat_message("assistant", avatar="ü§ñ"):
                    placeholder = st.empty()
                    display_text = ""
                    for char in assistant_text:
                        display_text += char
                        placeholder.markdown(display_text + "‚ñå")
                        time.sleep(0.01)
                    time.sleep(0.3)
                    placeholder.empty()
                    with st.container():
                        # highlight citations like [src:...] or [mem:...]
                        display_text_processed = re.sub(r'(\[src:[^\]]+\])', r'**\1**', assistant_text)
                        display_text_processed = re.sub(r'(\[mem:[^\]]+\])', r'**\1**', display_text_processed)
                        st.markdown("<div class='assistant-bubble'>", unsafe_allow_html=True)
                        st.markdown(display_text_processed)
                        st.markdown("</div>", unsafe_allow_html=True)
                        
                        # === HI·ªÇN TH·ªä NGU·ªíN THAM KH·∫¢O CHI TI·∫æT ===
                        if rag_used or intent_used or memory_used:
                            st.markdown("---")
                            st.subheader("üîç Ngu·ªìn tham kh·∫£o")
                            
                            # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ ChromaDB
                            if rag_used and sources_count > 0:
                                st.markdown(f'<div class="source-badge source-chroma">üìö <b>ChromaDB RAG</b>: S·ª≠ d·ª•ng {sources_count} t√†i li·ªáu t·ª´ c∆° s·ªü tri th·ª©c du l·ªãch</div>', unsafe_allow_html=True)
                            
                            if intent_used:
                                st.markdown(f'<div class="source-badge source-intent">üéØ <b>Intent Matching</b>: Ph√°t hi·ªán intent "{intent_used}" t·ª´ ChromaDB</div>', unsafe_allow_html=True)
                            
                            if memory_used:
                                st.markdown(f'<div class="source-badge source-memory">üí≠ <b>Memory Recall</b>: Tham kh·∫£o h·ªôi tho·∫°i tr∆∞·ªõc ƒë√≥ t·ª´ ChromaDB</div>', unsafe_allow_html=True)
                            
                            # Hi·ªÉn th·ªã chi ti·∫øt c√°c t√†i li·ªáu RAG
                            if "last_rag_docs" in st.session_state and st.session_state["last_rag_docs"]:
                                sources = st.session_state["last_rag_docs"]
                                with st.expander(f"üìñ Chi ti·∫øt {len(sources)} t√†i li·ªáu tham kh·∫£o"):
                                    for i, src in enumerate(sources, 1):
                                        meta = src.get("metadata", {}) or {}
                                        title = meta.get("title", "Kh√¥ng c√≥ ti√™u ƒë·ªÅ")
                                        city = meta.get("city", "")
                                        srcname = meta.get("source", "N·ªôi b·ªô")
                                        distance = src.get("distance")
                                        
                                        st.markdown(f"**{i}. {title}**")
                                        if city:
                                            st.caption(f"üìç {city}")
                                        if srcname:
                                            st.caption(f"üìö Ngu·ªìn: {srcname}")
                                        if distance is not None:
                                            st.caption(f"üìä ƒê·ªô t∆∞∆°ng ƒë·ªìng: {1 - distance:.3f}")
                                        st.markdown(f"*{src['text'][:200]}...*")
                                        st.markdown("---")

                # Log interaction v·ªõi th√¥ng tin RAG
                log_interaction(user_input, city_guess, start_date, end_date, intent_used, rag_used, sources_count)

                # === TTS (ƒë·ªçc to ph·∫£n h·ªìi) ===
                if tts_enable:
                    try:
                        tts = gTTS(assistant_text, lang=tts_lang)
                        bio = io.BytesIO()
                        tts.write_to_fp(bio)
                        bio.seek(0)
                        b64 = base64.b64encode(bio.read()).decode()
                        st.markdown(
                            f'<div class="audio-wrapper"><audio autoplay controls><source src="data:audio/mp3;base64,{b64}" type="audio/mp3"></audio></div>',
                            unsafe_allow_html=True
                        )
                    except Exception as e:
                        st.warning(f"Kh√¥ng th·ªÉ t·∫°o audio TTS: {e}")

                st.balloons()
            except Exception as e:
                st.error(f"‚ö†Ô∏è L·ªói khi g·ªçi OpenAI: {e}")

        lat, lon, addr = (None, None, None)
        if city_guess:
            lat, lon, addr = geocode_city(city_guess)
        cols = st.columns([2, 3])
        with cols[0]:
            if "Map" in info_options:
                show_map(lat, lon, zoom=map_zoom, title=addr or city_guess)
            if "Photos" in info_options:
                img = get_city_image(city_guess)
                if img:
                    st.image(img, caption=f"üèûÔ∏è {city_guess}", use_container_width=True)
                else:
                    st.info("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça.")
        with cols[1]:
            if "Food" in info_options:
                st.subheader(f"üçΩÔ∏è ·∫®m th·ª±c & Nh√† h√†ng t·∫°i {city_guess or 'ƒë·ªãa ƒëi·ªÉm'}")
                foods = get_local_foods_with_fallback(city_guess) if city_guess else []
                if foods:
                    st.markdown("#### ü•ò ƒê·∫∑c s·∫£n n·ªïi b·∫≠t")
                    food_images = get_food_images(foods)
                    img_cols = st.columns(min(len(food_images), 4))
                    for i, item in enumerate(food_images):
                        with img_cols[i % len(img_cols)]:
                            if item["image"]:
                                st.image(item["image"], caption=item["name"], use_container_width=True)
                            else:
                                st.write(f"- {item['name']}")
                else:
                    st.info("Kh√¥ng t√¨m th·∫•y m√≥n ƒë·∫∑c tr∆∞ng (CSV/GPT fallback kh√¥ng tr·∫£ k·∫øt qu·∫£).")
            if city_guess:
                st.markdown("#### üç¥ Nh√† h√†ng g·ª£i √Ω")
                restaurants = get_restaurants(city_guess, limit=5)
                if restaurants:
                    for r in restaurants:
                        if isinstance(r, dict) and r.get("error"):
                            st.write(f"‚ö†Ô∏è {r.get('error')}")
                        else:
                            name = r.get("name") or r.get("place_name") or str(r)
                            rating = r.get("rating", "")
                            addr_text = r.get("address", r.get("formatted_address", ""))
                            maps_url = r.get("maps_url", "")
                            st.markdown(f"- **{name}** {f'‚Ä¢ ‚≠ê {rating}' if rating else ''}  \n  {addr_text}  " + (f"[B·∫£n ƒë·ªì]({maps_url})" if maps_url else ""))
                else:
                    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu nh√† h√†ng (CSV/Google Places fallback).")

with analytics_tab:
    st.header("üìä Th·ªëng k√™ truy v·∫•n (g·∫ßn ƒë√¢y)")
    
    # Th√™m th·ªëng k√™ RAG - ƒê√É S·ª¨A L·ªñI
    try:
        conn = sqlite3.connect(DB_PATH)
        # Ki·ªÉm tra xem c·ªôt c√≥ t·ªìn t·∫°i kh√¥ng
        cur = conn.cursor()
        cur.execute("PRAGMA table_info(interactions)")
        columns = [col[1] for col in cur.fetchall()]
        
        df_logs = pd.read_sql("SELECT * FROM interactions ORDER BY timestamp DESC LIMIT 1000", conn)
        conn.close()
        
        if not df_logs.empty and 'rag_used' in columns:
            col1, col2, col3 = st.columns(3)
            with col1:
                total_rag = df_logs['rag_used'].sum()
                st.metric("Truy v·∫•n s·ª≠ d·ª•ng RAG", f"{total_rag}/{len(df_logs)}")
            with col2:
                avg_sources = df_logs['sources_count'].mean()
                st.metric("Trung b√¨nh ngu·ªìn/RAG", f"{avg_sources:.1f}")
            with col3:
                rag_rate = (total_rag / len(df_logs)) * 100
                st.metric("T·ª∑ l·ªá s·ª≠ d·ª•ng RAG", f"{rag_rate:.1f}%")
    except Exception as e:
        st.warning(f"Kh√¥ng th·ªÉ load th·ªëng k√™ RAG: {e}")
    
    with st.expander("üóëÔ∏è X√≥a l·ªãch s·ª≠ truy v·∫•n"):
        st.warning("‚ö†Ô∏è Thao t√°c n√†y s·∫Ω x√≥a to√†n b·ªô l·ªãch s·ª≠ truy v·∫•n ƒë√£ l∆∞u trong c∆° s·ªü d·ªØ li·ªáu (SQLite). Kh√¥ng th·ªÉ ho√†n t√°c.")
        confirm_delete = st.checkbox("T√¥i hi·ªÉu v√† mu·ªën x√≥a to√†n b·ªô l·ªãch s·ª≠ truy v·∫•n", value=False)
        if confirm_delete:
            if st.button("‚úÖ X√°c nh·∫≠n x√≥a to√†n b·ªô l·ªãch s·ª≠"):
                try:
                    conn = sqlite3.connect(DB_PATH)
                    cur = conn.cursor()
                    cur.execute("DELETE FROM interactions")
                    conn.commit()
                    conn.close()
                    st.success("‚úÖ ƒê√£ x√≥a to√†n b·ªô l·ªãch s·ª≠ truy v·∫•n.")
                except Exception as e:
                    st.error(f"‚ö†Ô∏è L·ªói khi x√≥a d·ªØ li·ªáu: {e}")
        else:
            st.info("üëâ H√£y tick v√†o √¥ x√°c nh·∫≠n tr∆∞·ªõc khi x√≥a l·ªãch s·ª≠.")
    
    try:
        conn = sqlite3.connect(DB_PATH)
        # Ki·ªÉm tra schema tr∆∞·ªõc khi query
        cur = conn.cursor()
        cur.execute("PRAGMA table_info(interactions)")
        columns = [col[1] for col in cur.fetchall()]
        
        # Ch·ªâ ch·ªçn c√°c c·ªôt t·ªìn t·∫°i
        select_columns = ["timestamp", "user_input", "city"]
        if 'rag_used' in columns:
            select_columns.extend(["rag_used", "sources_count"])
        if 'intent' in columns:
            select_columns.append("intent")
            
        df_logs = pd.read_sql(f"SELECT {', '.join(select_columns)} FROM interactions ORDER BY timestamp DESC LIMIT 1000", conn)
        conn.close()
        
        total = int(df_logs.shape[0]) if not df_logs.empty else 0
        st.metric("T·ªïng t∆∞∆°ng t√°c", total)
        
        if not df_logs.empty:
            df_logs['timestamp_dt'] = pd.to_datetime(df_logs['timestamp'])
            df_logs['date'] = df_logs['timestamp_dt'].dt.date
            
            # Bi·ªÉu ƒë·ªì s·ª≠ d·ª•ng RAG - ch·ªâ hi·ªÉn th·ªã n·∫øu c√≥ c·ªôt rag_used
            if 'rag_used' in df_logs.columns:
                rag_series = df_logs.groupby('date').agg({
                    'rag_used': 'sum',
                    'timestamp': 'count'
                }).reset_index()
                rag_series.columns = ['date', 'rag_queries', 'total_queries']
                rag_series['non_rag_queries'] = rag_series['total_queries'] - rag_series['rag_queries']
                
                fig_rag = px.bar(rag_series, x='date', y=['rag_queries', 'non_rag_queries'], 
                                title='üìà S·ª≠ d·ª•ng RAG theo ng√†y', 
                                color_discrete_map={'rag_queries': '#2196f3', 'non_rag_queries': '#ff9800'})
                st.plotly_chart(fig_rag, use_container_width=True)
            
            series = df_logs.groupby('date').size().reset_index(name='queries')
            fig = px.bar(series, x='date', y='queries', title='üìà S·ªë truy v·∫•n m·ªói ng√†y', color='queries', color_continuous_scale='Blues')
            st.plotly_chart(fig, use_container_width=True)
            
            top_cities = df_logs['city'].fillna("Unknown").value_counts().reset_index()
            top_cities.columns = ['city', 'count']
            if not top_cities.empty:
                fig2 = px.bar(top_cities.head(10), x='city', y='count', title='üìç Top ƒë·ªãa ƒëi·ªÉm ƒë∆∞·ª£c h·ªèi', color='count', color_continuous_scale='Viridis')
                st.plotly_chart(fig2, use_container_width=True)
            
            # Hi·ªÉn th·ªã chi ti·∫øt v·ªõi th√¥ng tin RAG
            st.dataframe(df_logs)
        else:
            st.info("Ch∆∞a c√≥ truy v·∫•n n√†o ƒë∆∞·ª£c ghi nh·∫≠n.")
    except Exception as e:
        st.warning(f"L·ªói ƒë·ªçc d·ªØ li·ªáu: {e}")

st.markdown("---")
st.markdown("<div class='small-muted'>Tip: B·∫°n c√≥ th·ªÉ y√™u c·∫ßu c·ª• th·ªÉ nh∆∞ 'L·ªãch tr√¨nh 3 ng√†y ·ªü H·ªôi An', 'ƒê·∫∑c s·∫£n Sapa', ho·∫∑c 'Th·ªùi ti·∫øt ƒê√† N·∫µng 2025-10-20 ƒë·∫øn 2025-10-22'.</div>", unsafe_allow_html=True)