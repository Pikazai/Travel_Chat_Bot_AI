# Travel_Chat_Bot_Enhanced_VOICE.py
# =================================
# M·ªü r·ªông: RAG (ChromaDB) + long-term memory + intent quick-match + recommendations
# Gi·ªØ l·∫°i to√†n b·ªô ch·ª©c nƒÉng g·ªëc (voice, TTS, weather, map, foods, restaurants...)
#
# Y√™u c·∫ßu:
#   pip install streamlit-mic-recorder SpeechRecognition pydub gTTS chromadb openai geopy pandas pydeck plotly
#   C√†i ffmpeg cho pydub
#

import streamlit as st
import openai
import json
import requests
import os
from datetime import datetime, timedelta
from geopy.geocoders import Nominatim
import pandas as pd
import sqlite3
import pydeck as pdk
import re
import time
import plotly.express as px

# === VOICE imports (m·ªõi) ===
import io
import base64
import tempfile
import subprocess
from streamlit_mic_recorder import mic_recorder
import speech_recognition as sr
from pydub import AudioSegment   # y√™u c·∫ßu ffmpeg
from gtts import gTTS

# === RAG / Chroma imports ===
from chromadb import PersistentClient
# NOTE: Replaced Client->PersistentClient for Chroma v1.2+# Chroma v1.2+ no longer uses chromadb.config.Settings
import uuid

# === Ensure single persistent Chroma client in Streamlit session ===
CHROMA_PERSIST_DIR = os.getenv("CHROMA_PERSIST_DIR", "chromadb_data")
# We'll create chroma_client lazily in init_chroma(), but ensure session key exists placeholder
# Actual ChromaClient will be created inside init_chroma using this CHROMA_PERSIST_DIR.

# -------------------------
st.set_page_config(page_title="[M√¢y Lang Thang] - Travel Assistant (Voice + RAG)", layout="wide", page_icon="ü§ñ")

# Global CSS + UI tweaks
st.markdown(
    """
    <style>
    :root{
      --primary:#2b4c7e;
      --accent:#e7f3ff;
      --muted:#f2f6fa;
    }
    body {
      background: linear-gradient(90deg, #f8fbff 0%, #eef5fa 100%);
      font-family: 'Segoe UI', Roboto, Arial, sans-serif;
    }
    .stApp > header {visibility: hidden;}
    h1, h2, h3 { color: var(--primary); }
    .sidebar-card { background-color:#f1f9ff; padding:10px; border-radius:10px; margin-bottom:8px;}
    .user-message { background: #f2f2f2; padding:10px; border-radius:12px; }
    .assistant-message { background: #e7f3ff; padding:10px; border-radius:12px; }
    .pill-btn { border-radius:999px !important; background:#e3f2fd !important; color:var(--primary) !important; padding:6px 12px; border: none; }
    .status-ok { background:#d4edda; padding:8px; border-radius:8px; }
    .status-bad { background:#f8d7da; padding:8px; border-radius:8px; }
    .small-muted { color: #6b7280; font-size:12px; }
    .logo-title { display:flex; align-items:center; gap:10px; }
    .logo-title h1 { margin:0; }
    .assistant-bubble {
      background-color: #e7f3ff;
      padding: 12px 16px;
      border-radius: 15px;
      margin-bottom: 6px;
    }
    .user-message {
      background-color: #f2f2f2;
      padding: 12px 16px;
      border-radius: 15px;
      margin-bottom: 6px;
    }
    /* HERO */
    .hero {
      position: relative;
      border-radius: 16px;
      overflow: hidden;
      box-shadow: 0 8px 30px rgba(43,76,126,0.12);
      margin-bottom: 18px;
    }
    .hero__bg {
      width: 100%;
      height: 320px;
      object-fit: cover;
      filter: brightness(0.65) saturate(1.05);
    }
    .hero__overlay {
      position: absolute;
      top: 0; left: 0; right: 0; bottom: 0;
      display: flex;
      align-items: center;
      justify-content: center;
      padding: 24px;
    }
    .hero__card {
      background: linear-gradient(90deg, rgba(255,255,255,0.02), rgba(255,255,255,0.08));
      backdrop-filter: blur(6px);
      border-radius: 12px;
      padding: 18px;
      width: 100%;
      max-width: 980px;
      color: white;
    }
    .hero__title { font-size: 28px; font-weight:700; margin:0 0 6px 0; color: #fff; }
    .hero__subtitle { margin:0 0 12px 0; color: #f0f6ff; }
    .hero__cta { display:flex; gap:8px; align-items:center; }
    @media (max-width: 768px) {
      .hero__bg { height: 220px; }
      .hero__title { font-size: 20px; }
    }
    .audio-wrapper {margin-top: 6px;}
    </style>
    """, unsafe_allow_html=True
)

# -------------------------
# CONFIG / SECRETS
# -------------------------
try:
    OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
except Exception:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", None)
OPENAI_ENDPOINT = st.secrets.get("OPENAI_ENDPOINT", "https://api.openai.com/v1") if hasattr(st, 'secrets') else os.getenv("OPENAI_ENDPOINT", "https://api.openai.com/v1")
DEPLOYMENT_NAME = st.secrets.get("DEPLOYMENT_NAME", "gpt-4o-mini") if hasattr(st, 'secrets') else os.getenv("DEPLOYMENT_NAME", "gpt-4o-mini")
OPENWEATHERMAP_API_KEY = st.secrets.get("OPENWEATHERMAP_API_KEY", "") if hasattr(st, 'secrets') else os.getenv("OPENWEATHERMAP_API_KEY", "")
GOOGLE_PLACES_KEY = st.secrets.get("PLACES_API_KEY", "") if hasattr(st, 'secrets') else os.getenv("PLACES_API_KEY", "")
PIXABAY_API_KEY = st.secrets.get("PIXABAY_API_KEY", "") if hasattr(st, 'secrets') else os.getenv("PIXABAY_API_KEY", "")
OPENAI_API_KEY_EMBEDDING = st.secrets["OPENAI_API_KEY_EMBEDDING"]

# Chroma persistent dir (t√πy ch·ªçn)
CHROMA_PERSIST_DIR = os.getenv("CHROMA_PERSIST_DIR", "chromadb_data")

# Initialize OpenAI client (using openai Python SDK modern interface)
if OPENAI_API_KEY:
    client = openai.OpenAI(base_url=OPENAI_ENDPOINT, api_key=OPENAI_API_KEY)
else:
    client = None

# --- Separate Embedding client (d√πng key ri√™ng) ---
try:
    OPENAI_API_KEY_EMBEDDING = st.secrets.get("OPENAI_API_KEY_EMBEDDING", None) if hasattr(st, 'secrets') else os.getenv("OPENAI_API_KEY_EMBEDDING", None)
except Exception:
    OPENAI_API_KEY_EMBEDDING = os.getenv("OPENAI_API_KEY_EMBEDDING", None)

if OPENAI_API_KEY_EMBEDDING:
    embedding_client = openai.OpenAI(base_url=OPENAI_ENDPOINT, api_key=OPENAI_API_KEY_EMBEDDING)
    # print("OPENAI_API_KEY_EMBEDDING: " + OPENAI_API_KEY_EMBEDDING)
else:
    embedding_client = client  # fallback n·∫øu ch∆∞a c√≥ key ri√™ng

ChatBotName = "[M√¢y Lang Thang]"  # display name
system_prompt = """
B·∫°n l√† H∆∞·ªõng d·∫´n vi√™n du l·ªãch ·∫£o Alex - ng∆∞·ªùi k·ªÉ chuy·ªán, am hi·ªÉu vƒÉn h√≥a, l·ªãch s·ª≠, ·∫©m th·ª±c v√† th·ªùi ti·∫øt Vi·ªát Nam.
Lu√¥n ƒë∆∞a ra th√¥ng tin h·ªØu √≠ch, g·ª£i √Ω l·ªãch tr√¨nh, m√≥n ƒÉn, chi ph√≠, th·ªùi gian l√Ω t∆∞·ªüng, s·ª± ki·ªán v√† g√≥c ch·ª•p ·∫£nh.
"""

# -------------------------
# DB LOGGING (SQLite)
# -------------------------
DB_PATH = "travel_chatbot_logs.db"

def init_db():
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("""
        CREATE TABLE IF NOT EXISTS interactions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            timestamp TEXT,
            user_input TEXT,
            city TEXT,
            start_date TEXT,
            end_date TEXT,
            intent TEXT
        )
    """)
    conn.commit()
    conn.close()

init_db()

def log_interaction(user_input, city=None, start_date=None, end_date=None, intent=None):
    conn = sqlite3.connect(DB_PATH)
    cur = conn.cursor()
    cur.execute("""
        INSERT INTO interactions (timestamp, user_input, city, start_date, end_date, intent)
        VALUES (?, ?, ?, ?, ?, ?)
    """, (datetime.utcnow().isoformat(), user_input, city,
          start_date.isoformat() if start_date else None,
          end_date.isoformat() if end_date else None,
          intent))
    conn.commit()
    conn.close()

# -------------------------
# CHROMA (RAG + Memory + Intent) INIT
# -------------------------


def safe_get_collection(client, name, expected_dim=1536):
    """
    Create or get a Chroma collection safely.
    Auto recreate collection if dimension mismatch or corruption occurs.
    Compatible with Chroma v1.2+ PersistentClient.
    """
    try:
        col = None
        try:
            col = client.get_collection(name)
        except Exception:
            # if get_collection not available, try get_or_create_collection
            try:
                col = client.get_or_create_collection(name=name)
            except Exception:
                pass
        if col is None:
            try:
                col = client.create_collection(name=name)
            except Exception:
                # fallback to get_or_create
                try:
                    col = client.get_or_create_collection(name=name)
                except Exception:
                    return None
        # Probe dimension by attempting a harmless query with expected_dim; delete if mismatch
        try:
            test_emb = [0.0] * expected_dim
            try:
                # newer chroma expects embeddings param name 'query_embeddings' or 'embeddings' depending on version
                col.query(query_embeddings=[test_emb], n_results=1)
            except Exception as qe:
                msg = str(qe).lower()
                if "dimension" in msg or "expected" in msg:
                    try:
                        print(f"üßπ Deleting collection {name} due to embedding-dimension mismatch ({qe})")
                        client.delete_collection(name=name)
                        # recreate
                        col = client.create_collection(name=name)
                    except Exception as de:
                        print(f"[WARN] Failed deleting/recreating collection {name}: {de}")
        except Exception:
            pass
        return col
    except Exception as e:
        print(f"[WARN] safe_get_collection failed for {name}: {e}")
        return None



def init_chroma():
    """
    Initialize Chroma persistent client and ensure collections exist.
    Compatible with Chroma v1.2+ using PersistentClient.
    """
    global chroma_client, chroma_travel_col, chroma_memory_col, chroma_intent_col
    EXPECTED_DIM = 1536
    # persist dir (project-local)
    persist_dir = os.path.join(os.getcwd(), "chromadb_data")
    try:
        # Use PersistentClient for new Chroma versions
        from chromadb import PersistentClient
        # create or reuse client in st.session_state
        if "chroma_client" not in st.session_state or st.session_state.get("chroma_client") is None:
            st.session_state["chroma_client"] = PersistentClient(path=persist_dir)
            print("[INIT] Created PersistentClient for Chroma at", persist_dir)
        else:
            print("[DEBUG] Reusing existing PersistentClient in session_state")
        chroma_client = st.session_state["chroma_client"]
    except Exception as e:
        print(f"[WARN] Failed to init PersistentClient: {e}")
        try:
            # fallback: try to use PersistentClient directly without session_state
            chroma_client = PersistentClient(path=persist_dir)
        except Exception as e2:
            print(f"[ERROR] PersistentClient fallback failed: {e2}")
            return None, None, None, None
    # --- Force scan and delete any 384-dimension collections ---
    try:
        for col in chroma_client.list_collections():
            cname = getattr(col, "name", str(col))
            try:
                emb = [0.0] * EXPECTED_DIM
                col.query(query_embeddings=[emb], n_results=1)
            except Exception as qe:
                if "384" in str(qe):
                    print(f"üßπ Force deleting old collection {cname} (384-dim detected)")
                    try:
                        chroma_client.delete_collection(name=cname)
                    except Exception as de:
                        print(f"[WARN] Could not delete old collection {cname}: {de}")
    except Exception as e:
        print(f"[WARN] Force cleanup skipped: {e}")

    except Exception as e:
        print(f"[WARN] Failed to init PersistentClient: {e}")
        try:
            # fallback: try to use PersistentClient directly without session_state
            chroma_client = PersistentClient(path=persist_dir)
        except Exception as e2:
            print(f"[ERROR] PersistentClient fallback failed: {e2}")
            return None, None, None, None

    # ensure persist dir exists
    try:
        os.makedirs(persist_dir, exist_ok=True)
    except Exception:
        pass
    try:
        st.sidebar.markdown(f"üß† **Chroma DB:** `{os.path.abspath(persist_dir)}`")
    except Exception:
        pass

    # Attempt to cleanup any existing collections with mismatched dimension
    try:
        existing = []
        try:
            existing = chroma_client.list_collections()
        except Exception:
            try:
                existing = [c.name for c in chroma_client.get_collections()]  # older API
            except Exception:
                existing = []
        names = []
        for item in existing:
            if isinstance(item, dict) and item.get("name"):
                names.append(item["name"])
            elif isinstance(item, str):
                names.append(item)
            else:
                try:
                    n = getattr(item, "name", None)
                    if n:
                        names.append(n)
                except Exception:
                    pass
        candidate_names = set(names)
        candidate_names.update(["vietnam_travel", "chat_memory", "intent_bank",
                                "vietnam_travel_v2", "chat_memory_v2", "intent_bank_v2"])
        for cname in list(candidate_names):
            try:
                col = chroma_client.get_collection(name=cname)
            except Exception:
                # some APIs use different signature
                try:
                    col = chroma_client.get_collection(cname)
                except Exception:
                    continue
            try:
                test_emb = [0.0] * EXPECTED_DIM
                try:
                    col.query(query_embeddings=[test_emb], n_results=1)
                except Exception as qe:
                    msg = str(qe).lower()
                    if "dimension" in msg or "expected" in msg:
                        try:
                            print(f"üßπ Deleting collection {cname} due to embedding-dimension mismatch ({qe})")
                            chroma_client.delete_collection(name=cname)
                        except Exception as de:
                            print(f"[WARN] Failed deleting collection {cname}: {de}")
            except Exception:
                # fallback: inspect attribute
                try:
                    col_dim = getattr(col, "dimension", None)
                    if col_dim and col_dim != EXPECTED_DIM:
                        try:
                            chroma_client.delete_collection(name=cname)
                        except Exception:
                            pass
                except Exception:
                    pass
    except Exception as e:
        print(f"[WARN] Error when scanning collections: {e}")

    # create/get our important collections
    travel_col = safe_get_collection(chroma_client, "vietnam_travel_v2", expected_dim=EXPECTED_DIM)
    memory_col = safe_get_collection(chroma_client, "chat_memory_v2", expected_dim=EXPECTED_DIM)
    intent_col = safe_get_collection(chroma_client, "intent_bank_v2", expected_dim=EXPECTED_DIM)

    print("‚úÖ Chroma collections ready (or created):", 
          f"travel={'OK' if travel_col else 'NO'}, memory={'OK' if memory_col else 'NO'}, intent={'OK' if intent_col else 'NO'}")
    print(f"‚úÖ Chroma initialized: travel={bool(travel_col)}, memory={bool(memory_col)}, intent={bool(intent_col)}")
    return chroma_client, travel_col, memory_col, intent_col

    # Scan existing collections and delete those with mismatched embedding dimension
    try:
        existing = []
        try:
            existing = chroma_client.list_collections()
        except Exception:
            existing = []

        names = []
        for item in existing:
            if isinstance(item, dict) and item.get("name"):
                names.append(item["name"])
            elif isinstance(item, str):
                names.append(item)
            else:
                try:
                    n = getattr(item, "name", None)
                    if n:
                        names.append(n)
                except Exception:
                    pass

        # include legacy names we care about
        candidate_names = set(names)
        candidate_names.update(["vietnam_travel", "chat_memory", "intent_bank",
                                "vietnam_travel_v2", "chat_memory_v2", "intent_bank_v2"])

        for cname in list(candidate_names):
            try:
                col = chroma_client.get_collection(cname)
            except Exception:
                continue
            try:
                # probe with a test embedding of EXPECTED_DIM
                test_emb = [0.0] * EXPECTED_DIM
                try:
                    col.query(query_embeddings=[test_emb], n_results=1, include=["documents"])
                    # if no exception -> likely dimension matches
                except Exception as qe:
                    msg = str(qe).lower()
                    if "dimension" in msg or "expected" in msg or "384" in msg:
                        print(f"üßπ Deleting collection {cname} due to embedding-dimension mismatch (error: {qe})")
                        try:
                            chroma_client.delete_collection(cname)
                        except Exception as de:
                            print(f"[WARN] Failed deleting collection {cname}: {de}")
                    else:
                        # unknown error - ignore
                        pass
            except Exception:
                try:
                    col_dim = getattr(col, "dimension", None)
                    if col_dim and col_dim != EXPECTED_DIM:
                        print(f"üßπ Deleting collection {cname} (col.dimension={col_dim} != {EXPECTED_DIM})")
                        try:
                            chroma_client.delete_collection(cname)
                        except Exception as de:
                            print(f"[WARN] Failed deleting collection {cname}: {de}")
                except Exception:
                    pass
    except Exception as e:
        print(f"[WARN] Error when scanning/deleting old collections: {e}")

    # create/get collections safely
    travel_col = safe_get_collection(chroma_client, "vietnam_travel_v2", expected_dim=EXPECTED_DIM)
    memory_col = safe_get_collection(chroma_client, "chat_memory_v2", expected_dim=EXPECTED_DIM)
    intent_col = safe_get_collection(chroma_client, "intent_bank_v2", expected_dim=EXPECTED_DIM)

    print("‚úÖ Chroma collections ready (or created):",
          f"travel={'OK' if travel_col else 'NO'}, memory={'OK' if memory_col else 'NO'}, intent={'OK' if intent_col else 'NO'}")
    print(f"‚úÖ Chroma initialized: travel={bool(travel_col)}, memory={bool(memory_col)}, intent={bool(intent_col)}")
    return chroma_client, travel_col, memory_col, intent_col

# --- Initialize Chroma client and collections once (and store in session_state/global) ---
try:
    chroma_client, chroma_travel_col, chroma_memory_col, chroma_intent_col = init_chroma()
except Exception as e:
    chroma_client = chroma_travel_col = chroma_memory_col = chroma_intent_col = None
    print(f"[WARN] init_chroma() failed: {e}")

# Safe preload intents if function exists
if 'preload_intents' in globals() and callable(globals()['preload_intents']):
    try:
        preload_intents()
    except Exception as e:
        print(f"[WARN] preload_intents failed: {e}")

# -------------------------
# UTILITIES: days extraction (original logic)
# -------------------------
def extract_days_from_text(user_text, start_date=None, end_date=None):
    if start_date and end_date:
        try:
            delta = (end_date - start_date).days + 1
            return max(delta, 1)
        except Exception:
            pass
    m = re.search(r"(\d+)\s*(ng√†y|day|days|tu·∫ßn|week|weeks)", user_text, re.IGNORECASE)
    if m:
        num = int(m.group(1))
        unit = m.group(2).lower()
        if "tu·∫ßn" in unit or "week" in unit:
            return num * 7
        return num
    if client:
        try:
            prompt = f"""
B·∫°n l√† m·ªôt b·ªô ph√¢n t√≠ch ng·ªØ nghƒ©a ti·∫øng Vi·ªát & ti·∫øng Anh.
X√°c ƒë·ªãnh ng∆∞·ªùi d√πng mu·ªën n√≥i bao nhi√™u ng√†y trong c√¢u sau, n·∫øu kh√¥ng c√≥ th√¨ m·∫∑c ƒë·ªãnh 3:
Tr·∫£ v·ªÅ JSON: {{"days": <s·ªë nguy√™n>}}
C√¢u: "{user_text}"
"""
            response = client.chat.completions.create(
                model=DEPLOYMENT_NAME,
                messages=[{"role": "system", "content": prompt}],
                max_tokens=50,
                temperature=0
            )
            text = response.choices[0].message.content.strip()
            num_match = re.search(r'"days"\s*:\s*(\d+)', text)
            if num_match:
                return int(num_match.group(1))
        except Exception:
            pass
    return 3

# -------------------------
# GEOCODING & MAPS
# -------------------------
geolocator = Nominatim(user_agent="travel_chatbot_app")

def geocode_city(city_name):
    try:
        loc = geolocator.geocode(city_name, country_codes="VN", timeout=10)
        if loc:
            return loc.latitude, loc.longitude, loc.address
        return None, None, None
    except Exception:
        return None, None, None

def show_map(lat, lon, zoom=8, title=""):
    if lat is None or lon is None:
        st.info("Kh√¥ng c√≥ d·ªØ li·ªáu to·∫° ƒë·ªô ƒë·ªÉ hi·ªÉn th·ªã b·∫£n ƒë·ªì.")
        return

    lat, lon = float(lat), float(lon)

    st.write(f"**V·ªã tr√≠:** {title} ({lat:.5f}, {lon:.5f})")

    view_state = pdk.ViewState(latitude=lat, longitude=lon, zoom=zoom)

    layer = pdk.Layer(
        "ScatterplotLayer",
        data=pd.DataFrame([{"lat": lat, "lon": lon}]),
        get_position='[lon, lat]',
        get_radius=2000,
        get_fill_color=[255, 0, 0],
        get_line_color=[0, 0, 0],
        line_width_min_pixels=1,
        pickable=True,
        opacity=0.9,
    )

    marker_layer = pdk.Layer(
        "TextLayer",
        data=pd.DataFrame([{"lat": lat, "lon": lon, "name": "üìç"}]),
        get_position='[lon, lat]',
        get_text="name",
        get_size=24,
        get_color=[200, 30, 30],
        billboard=True,
    )

    deck = pdk.Deck(
        layers=[layer, marker_layer],
        initial_view_state=view_state,
        map_style="https://basemaps.cartocdn.com/gl/positron-gl-style/style.json",
        tooltip={"text": title or "V·ªã tr√≠"},
    )

    st.pydeck_chart(deck)

# -------------------------
# WEATHER (OpenWeatherMap) with AI fallback on location
# -------------------------
def resolve_city_via_ai(user_text):
    if not client:
        return None
    try:
        prompt = f"""
B·∫°n l√† chuy√™n gia ƒë·ªãa l√Ω du l·ªãch Vi·ªát Nam.
Ph√¢n t√≠ch c√¢u sau ƒë·ªÉ x√°c ƒë·ªãnh:
1. 'place': ƒë·ªãa danh c·ª• th·ªÉ
2. 'province_or_city': t·ªânh/th√†nh c·ªßa Vi·ªát Nam ch·ª©a ƒë·ªãa danh ƒë√≥.
N·∫øu kh√¥ng x√°c ƒë·ªãnh ƒë∆∞·ª£c, tr·∫£ v·ªÅ null.
JSON v√≠ d·ª•: {{"place":"Phong Nha - K·∫ª B√†ng","province_or_city":"Qu·∫£ng B√¨nh"}}
C√¢u: "{user_text}"
"""
        response = client.chat.completions.create(
            model=DEPLOYMENT_NAME,
            messages=[{"role": "system", "content": prompt}],
            max_tokens=200,
            temperature=0
        )
        text = response.choices[0].message.content.strip()
        start, end = text.find("{"), text.rfind("}")
        if start == -1 or end == -1:
            return None
        data = json.loads(text[start:end+1])
        return data.get("province_or_city")
    except Exception:
        return None

def get_weather_forecast(city_name, start_date=None, end_date=None, user_text=None):
    if not OPENWEATHERMAP_API_KEY:
        return "‚ö†Ô∏è Thi·∫øu OpenWeatherMap API Key."
    
    if start_date is None or end_date is None:
        today = datetime.now().date()
        start_date = datetime.combine(today, datetime.min.time())
        end_date = datetime.combine(today + timedelta(days=3), datetime.min.time())
    
    try:
        def _fetch_weather(city):
            url = f"http://api.openweathermap.org/data/2.5/forecast?q={city}&appid={OPENWEATHERMAP_API_KEY}&lang=vi&units=metric"
            response = requests.get(url, timeout=8)
            return response.json()
        data = _fetch_weather(city_name)
        if data.get("cod") != "200" and user_text:
            ai_city = resolve_city_via_ai(user_text)
            if ai_city and ai_city.lower() != city_name.lower():
                data = _fetch_weather(f"{ai_city},VN")
                city_name = ai_city
        if data.get("cod") != "200":
            return f"‚ùå Kh√¥ng t√¨m th·∫•y th√¥ng tin d·ª± b√°o th·ªùi ti·∫øt cho ƒë·ªãa ƒëi·ªÉm: **{city_name}**."
        forecast_text = f"üå§ **D·ª± b√°o th·ªùi ti·∫øt cho {city_name}:**\n"
        if start_date and end_date:
            current = start_date
            while current <= end_date:
                date_str = current.strftime("%Y-%m-%d")
                day_forecasts = [f for f in data['list'] if f['dt_txt'].startswith(date_str)]
                if not day_forecasts:
                    forecast_text += f"\nüìÖ {current.strftime('%d/%m/%Y')}: Kh√¥ng c√≥ d·ªØ li·ªáu d·ª± b√°o.\n"
                else:
                    temps = [f['main']['temp'] for f in day_forecasts]
                    desc = day_forecasts[0]['weather'][0]['description']
                    forecast_text += (
                        f"\nüìÖ {current.strftime('%d/%m/%Y')} - {desc.capitalize()}\n"
                        f"üå° Nhi·ªát ƒë·ªô trung b√¨nh: {sum(temps)/len(temps):.1f}¬∞C\n"
                    )
                current += timedelta(days=1)
        else:
            first_forecast = data['list'][0]
            desc = first_forecast['weather'][0]['description'].capitalize()
            temp = first_forecast['main']['temp']
            forecast_text += f"- Hi·ªán t·∫°i: {desc}, {temp}¬∞C\n"
        return forecast_text
    except Exception as e:
        return f"‚ö†Ô∏è L·ªói khi l·∫•y d·ªØ li·ªáu th·ªùi ti·∫øt: {e}"

# -------------------------
# PIXABAY IMAGE FUNCTIONS
# -------------------------
def get_pixabay_image(query, per_page=3):
    if not PIXABAY_API_KEY:
        return None
    try:
        url = "https://pixabay.com/api/"
        params = {
            "key": PIXABAY_API_KEY,
            "q": query,
            "image_type": "photo",
            "orientation": "horizontal",
            "safesearch": "true",
            "per_page": per_page,
        }
        res = requests.get(url, params=params, timeout=8)
        data = res.json()
        if data.get("hits"):
            return data["hits"][0].get("largeImageURL") or data["hits"][0].get("webformatURL")
        return None
    except Exception:
        return None

def get_city_image(city):
    if not city:
        return None
    queries = [
        f"{city} Vietnam landscape",
        f"{city} Vietnam city",
        f"{city} Vietnam travel",
        "Vietnam travel landscape"
    ]
    for q in queries:
        img = get_pixabay_image(q)
        if img:
            return img
    return "https://via.placeholder.com/1200x800?text=No+Image"

def get_food_images(food_list):
    images = []
    for food in food_list[:5]:
        query = f"{food} Vietnam food"
        img_url = get_pixabay_image(query)
        if not img_url:
            img_url = "https://via.placeholder.com/400x300?text=No+Image"
        images.append({"name": food, "image": img_url})
    return images

# -------------------------
# RESTAURANTS HYBRID (Google Places + CSV fallback)
# -------------------------
def get_restaurants_google(city, api_key, limit=5):
    try:
        query = f"nh√† h√†ng t·∫°i {city}, Vi·ªát Nam"
        url = "https://maps.googleapis.com/maps/api/place/textsearch/json"
        params = {"query": query, "key": api_key, "language": "vi"}
        res = requests.get(url, params=params, timeout=10).json()
        if "error_message" in res:
            return [{"error": res["error_message"]}]
        results = []
        for r in res.get("results", [])[:limit]:
            results.append({
                "name": r.get("name"),
                "rating": r.get("rating", "N/A"),
                "address": r.get("formatted_address", ""),
                "maps_url": f"https://www.google.com/maps/place/?q=place_id:{r.get('place_id')}"
            })
        return results
    except Exception as e:
        return [{"error": str(e)}]

def get_local_restaurants(city, limit=5):
    try:
        df = pd.read_csv("data/restaurants_vn.csv")
        df_city = df[df["city"].str.lower().str.contains(str(city).lower(), na=False)]
        if df_city.empty:
            return []
        return df_city.head(limit).to_dict("records")
    except Exception:
        return []

def get_restaurants(city, limit=5):
    if not city:
        return []
    if GOOGLE_PLACES_KEY:
        data = get_restaurants_google(city, GOOGLE_PLACES_KEY, limit)
        if data and not data[0].get("error"):
            return data
    return get_local_restaurants(city, limit)

# -------------------------
# FOOD AI ASSISTANT (CSV + GPT fallback)
# -------------------------
def re_split_foods(s):
    for sep in [",", "|", ";"]:
        if sep in s:
            return [p.strip() for p in s.split(sep) if p.strip()]
    return [s.strip()]

def get_local_foods(city):
    try:
        df = pd.read_csv("data/vietnam_foods.csv", dtype=str)
        mask = df["city"].str.lower().str.contains(str(city).lower(), na=False)
        row = df[mask]
        if not row.empty:
            row0 = row.iloc[0]
            if "foods" in row0.index:
                foods_cell = row0["foods"]
                if pd.notna(foods_cell):
                    return re_split_foods(foods_cell)
            else:
                vals = row0.dropna().tolist()
                if len(vals) > 1:
                    return [v for v in vals[1:]]
    except Exception:
        pass
    return []

def get_foods_via_gpt(city, max_items=5):
    if not client:
        return []
    try:
        prompt = (
            f"You are an expert on Vietnamese cuisine.\n"
            f"List up to {max_items} iconic or must-try dishes from the city/region '{city}'.\n"
            "Return only a comma-separated list of dish names (no extra text)."
        )
        response = client.chat.completions.create(
            model=DEPLOYMENT_NAME,
            messages=[{"role":"system","content":prompt}],
            max_tokens=150,
            temperature=0.5
        )
        text = response.choices[0].message.content.strip()
        items = [t.strip() for t in text.split(",") if t.strip()]
        return items[:max_items]
    except Exception:
        return []

def get_local_foods_with_fallback(city):
    foods = get_local_foods(city)
    if not foods:
        foods = get_foods_via_gpt(city)
    return foods

# -------------------------
# SUGGESTIONS / COST / PHOTOSPOTS
# -------------------------
def estimate_cost(city, days=3, people=1, style="trung b√¨nh"):
    mapping = {"ti·∫øt ki·ªám": 400000, "trung b√¨nh": 800000, "cao c·∫•p": 2000000}
    per_day = mapping.get(style, 800000)
    total = per_day * days * people
    return f"üí∏ Chi ph√≠ ∆∞·ªõc t√≠nh: kho·∫£ng {total:,} VNƒê cho {people} ng∆∞·ªùi, {days} ng√†y."

def suggest_local_food(city):
    return f"üçú G√µ 'ƒê·∫∑c s·∫£n {city}' ƒë·ªÉ nh·∫≠n danh s√°ch m√≥n ƒÉn n·ªïi b·∫≠t."

def suggest_events(city):
    return f"üéâ S·ª± ki·ªán ·ªü {city}: l·ªÖ h·ªôi ƒë·ªãa ph∆∞∆°ng, ch·ª£ ƒë√™m, h·ªôi ch·ª£ ·∫©m th·ª±c (tu·ª≥ m√πa)."

def suggest_photospots(city):
    return f"üì∏ G·ª£i √Ω check-in: trung t√¢m l·ªãch s·ª≠, b·ªù s√¥ng/bi·ªÉn, qu√°n c√† ph√™ c√≥ view ƒë·∫πp."

# -------------------------
# BILINGUAL CITY & DATE EXTRACTION
# -------------------------
def extract_city_and_dates(user_text):
    if not client:
        return None, None, None
    try:
        prompt = f"""
You are a multilingual travel information extractor.
Extract 'city','start_date','end_date' (YYYY-MM-DD). If only one date is provided, set both to that date.
Return JSON only.
Message: "{user_text}"
"""
        response = client.chat.completions.create(
            model=DEPLOYMENT_NAME,
            messages=[{"role":"system","content":prompt}],
            max_tokens=200,
            temperature=0
        )
        content = response.choices[0].message.content.strip()
        start = content.find('{')
        end = content.rfind('}')
        if start == -1 or end == -1:
            return None, None, None
        data = json.loads(content[start:end+1])
        city = data.get("city")
        s = data.get("start_date")
        e = data.get("end_date")
        def _parse(d):
            if not d:
                return None
            dt = datetime.strptime(d, "%Y-%m-%d")
            return dt
        start_dt = _parse(s)
        end_dt = _parse(e)
        if start_dt and not end_dt:
            end_dt = start_dt
        return city, start_dt, end_dt
    except Exception:
        return None, None, None

# -------------------------
# RAG / Chroma helper functions
# -------------------------
def get_embedding_openai(text):
    """
    Tr·∫£ v·ªÅ embedding list b·∫±ng model text-embedding-3-small.
    S·ª≠ d·ª•ng embedding_client (c√≥ key ri√™ng).
    """
    if not embedding_client:
        return None
    try:
        emb_resp = embedding_client.embeddings.create(
            model="text-embedding-3-small",
            input=text
        )
        return emb_resp.data[0].embedding
    except Exception as e:
        print(f"[WARN] embedding failed: {e}")
        return None

def rag_query_top_k(user_text, k=5):
    """
    L·∫•y top-k ƒëo·∫°n vƒÉn t·ª´ collection vietnam_travel b·∫±ng embedding.
    Tr·∫£ v·ªÅ list dict v√† context string.
    """
    if chroma_travel_col is None or client is None:
        return [], ""
    emb = get_embedding_openai(user_text)
    if emb is None:
        return [], ""
    try:
        res = chroma_travel_col.query(query_embeddings=[emb], n_results=k, include=["documents","metadatas","distances"])
        docs = []
        # robust parsing for different chroma versions
        try:
            docs_texts = res["documents"][0]
            metadatas = res.get("metadatas",[[]])[0] if res.get("metadatas") else [None]*len(docs_texts)
            ids = res.get([[]])[0] if res.get("ids") else [None]*len(docs_texts)
            distances = res.get("distances",[[]])[0] if res.get("distances") else [None]*len(docs_texts)
            for i, txt in enumerate(docs_texts):
                docs.append({"id": ids[i] or str(uuid.uuid4()),
                             "text": txt,
                             "metadata": metadatas[i] or {},
                             "distance": distances[i] if i < len(distances) else None})
        except Exception:
            # fallback if different shape
            try:
                docs_texts = res["documents"]
                for i, txt in enumerate(docs_texts):
                    md = res.get("metadatas",[{}])[i] if res.get("metadatas") else {}
                    _id = res.get([None])[i] if res.get("ids") else str(uuid.uuid4())
                    dist = res.get("distances",[None])[i] if res.get("distances") else None
                    docs.append({"id": _id, "text": txt, "metadata": md, "distance": dist})
            except Exception:
                pass
        context_parts = []
        for d in docs:
            src = d["metadata"].get("source", "") if isinstance(d.get("metadata"), dict) else ""
            context_parts.append(f"[src:{d['id']}{('|' + src) if src else ''}] {d['text'][:1200]}")
        context = "\n\n".join(context_parts)
        st.session_state["last_rag_docs"] = docs  # l∆∞u ngu·ªìn v√†o session
        return docs, context
    except Exception as e:
        print(f"[WARN] chroma query error: {e}")
        return [], ""

def add_to_memory_collection(text, role="user", city=None, extra_meta=None):
    """
    L∆∞u embedding + text v√†o collection chat_memory.
    """
    if chroma_memory_col is None or client is None:
        return
    try:
        emb = get_embedding_openai(text)
        doc_id = f"mem_{int(time.time()*1000)}_{uuid.uuid4().hex[:8]}"
        meta = {"role": role, "city": city or "", "timestamp": datetime.utcnow().isoformat()}
        if extra_meta and isinstance(extra_meta, dict):
            meta.update(extra_meta)
        # Some chroma versions accept embeddings param, others compute embedding on add
        try:
            chroma_memory_col.add(documents=[text], metadatas=[meta], ids=[doc_id], embeddings=[emb])
        except TypeError:
            # fallback without embeddings param
            chroma_memory_col.add(documents=[text], metadatas=[meta], ids=[doc_id])
    except Exception as e:
        print(f"[WARN] add to memory failed: {e}")

def recall_recent_memories(user_text, k=5):
    """
    Truy v·∫•n chat_memory b·∫±ng embedding user_text ƒë·ªÉ l·∫•y c√°c ƒëo·∫°n h·ªôi tho·∫°i g·∫ßn nh·∫•t.
    """
    if chroma_memory_col is None or client is None:
        return []
    emb = get_embedding_openai(user_text)
    if emb is None:
        return []
    try:
        res = chroma_memory_col.query(query_embeddings=[emb], n_results=k, include=["documents","metadatas","distances"])
        items = []
        docs_texts = res.get("documents", [[]])[0] if res.get("documents") else []
        metadatas = res.get("metadatas", [[]])[0] if res.get("metadatas") else []
        ids = res.get( [[]])[0] if res.get("ids") else []
        distances = res.get("distances", [[]])[0] if res.get("distances") else [None]*len(docs_texts)
        for i, t in enumerate(docs_texts):
            items.append({"id": ids[i] if i < len(ids) else None, "text": t, "meta": metadatas[i] if i < len(metadatas) else {}, "distance": distances[i] if i < len(distances) else None})
        return items
    except Exception as e:
        print(f"[WARN] recall error: {e}")
        return []

def get_intent_via_chroma(user_text, threshold=0.2):
    """
    Truy v·∫•n intent_bank t√¨m intent g·∫ßn nh·∫•t. N·∫øu distance < threshold => tr·∫£ v·ªÅ intent id.
    """
    if chroma_intent_col is None or client is None:
        return None
    emb = get_embedding_openai(user_text)
    if emb is None:
        return None
    try:
        res = chroma_intent_col.query(query_embeddings=[emb], n_results=1, include=["metadatas","distances"])
        distances = res.get("distances", [[]])[0] if res.get("distances") else []
        metadatas = res.get("metadatas", [[]])[0] if res.get("metadatas") else []
        if distances and distances[0] is not None and distances[0] < threshold:
            return metadatas[0].get("intent") if isinstance(metadatas[0], dict) else None
    except Exception as e:
        print(f"[WARN] intent chroma error: {e}")
    return None

def recommend_similar_trips(city, k=3):
    """
    T√¨m trong chat_memory c√°c trips t∆∞∆°ng t·ª± d·ª±a tr√™n city (ho·∫∑c m√¥ t·∫£).
    """
    if chroma_memory_col is None:
        return []
    emb = get_embedding_openai(city)
    if emb is None:
        return []
    try:
        res = chroma_memory_col.query(query_embeddings=[emb], n_results=10, include=["documents","metadatas","distances"])
        docs = res.get("documents", [[]])[0] if res.get("documents") else []
        metas = res.get("metadatas", [[]])[0] if res.get("metadatas") else []
        ids = res.get( [[]])[0] if res.get("ids") else []
        recommendations = []
        for i, m in enumerate(metas):
            rec_city = m.get("city") if isinstance(m, dict) else None
            if rec_city and rec_city.lower() != city.lower() and rec_city not in [r.get("city") for r in recommendations]:
                recommendations.append({"city": rec_city, "meta": m, "doc": docs[i] if i < len(docs) else "", "id": ids[i] if i < len(ids) else None})
            if len(recommendations) >= k:
                break
        return recommendations
    except Exception as e:
        print(f"[WARN] recommend error: {e}")
        return []

# preload intents samples
def preload_intents():
    if chroma_intent_col is None or client is None:
        return
    try:
        samples = [
            ("Th·ªùi ti·∫øt ·ªü {city} tu·∫ßn t·ªõi?", {"intent":"weather_query"}),
            ("L·ªãch tr√¨nh 3 ng√†y ·ªü {city}", {"intent":"itinerary_request"}),
            ("ƒê·∫∑c s·∫£n {city}", {"intent":"food_query"}),
            ("G·ª£i √Ω nh√† h√†ng ·ªü {city}", {"intent":"restaurant_query"})
        ]
        docs = []
        metas = []
        ids = []
        for i, (t, meta) in enumerate(samples):
            docs.append(t)
            metas.append(meta)
            ids.append(f"intent_sample_{i}")
        chroma_intent_col.add(documents=docs, metadatas=metas, ids=ids)
    except Exception as e:
        print(f"[WARN] preload intents: {e}")

try:
    preload_intents()
except Exception:
    pass

# -------------------------
# HERO / HEADER SECTION
# -------------------------
def render_hero_section(default_city_hint="H·ªôi An, ƒê√† N·∫µng, H√† N·ªôi..."):
    with st.form(key='hero_search_form', clear_on_submit=False):
        cols = st.columns([3,2,1,1])
        dest = cols[0].text_input("ƒêi·ªÉm ƒë·∫øn", placeholder=default_city_hint)
        dates = cols[1].date_input("Ng√†y (b·∫Øt ƒë·∫ßu / k·∫øt th√∫c)", [])
        people = cols[2].selectbox("Ng∆∞·ªùi", [1,2,3,4,5,6], index=0)
        style = cols[3].selectbox("M·ª©c chi", ["trung b√¨nh", "ti·∫øt ki·ªám", "cao c·∫•p"], index=0)
        submitted = st.form_submit_button("G·ª£i √Ω nhanh", use_container_width=True)
        if submitted:
            if len(dates) == 2:
                s = dates[0].strftime("%Y-%m-%d")
                e = dates[1].strftime("%Y-%m-%d")
                q = f"L·ªãch tr√¨nh { ( (dates[1]-dates[0]).days +1 ) } ng√†y ·ªü {dest} t·ª´ {s} ƒë·∫øn {e}"
            elif len(dates) == 1:
                s = dates[0].strftime("%Y-%m-%d")
                q = f"L·ªãch tr√¨nh 1 ng√†y ·ªü {dest} v√†o {s}"
            else:
                q = f"L·ªãch tr√¨nh 3 ng√†y ·ªü {dest}"
            q += f" ‚Ä¢ ng∆∞·ªùi: {people} ‚Ä¢ m·ª©c: {style}"
            st.session_state.user_input = q
            st.rerun()

# -------------------------
# VOICE HELPERS
# -------------------------
def detect_audio_type_header(b):
    if len(b) < 12:
        return None
    if b[0:4] == b'RIFF' and b[8:12] == b'WAVE':
        return 'wav'
    if b[0:4] == b'fLaC':
        return 'flac'
    if b[0:4] == b'OggS':
        return 'ogg'
    if b[0:4] == b'\x1A\x45\xDF\xA3':
        return 'webm'
    if b[0:3] == b'ID3' or b[0] == 0xFF:
        return 'mp3'
    return None

def write_temp_file_and_convert_to_wav(audio_bytes):
    header = audio_bytes[:64]
    atype = detect_audio_type_header(header)
    ext_map = {'wav': '.wav', 'ogg': '.ogg', 'webm': '.webm', 'mp3': '.mp3', 'flac': '.flac'}
    ext = ext_map.get(atype, '.webm')
    tmp_dir = tempfile.mkdtemp()
    src_path = os.path.join(tmp_dir, "input" + ext)
    wav_path = os.path.join(tmp_dir, "converted.wav")
    with open(src_path, "wb") as f:
        f.write(audio_bytes)
    if atype == 'wav':
        return src_path
    try:
        audio = AudioSegment.from_file(src_path)
        audio = audio.set_frame_rate(16000).set_channels(1)
        audio.export(wav_path, format="wav")
        return wav_path
    except Exception as e:
        try:
            cmd = ["ffmpeg", "-y", "-i", src_path, "-ar", "16000", "-ac", "1", wav_path]
            subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
            return wav_path
        except Exception as e2:
            raise RuntimeError(f"Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi audio sang WAV: {e} | {e2}")

# -------------------------
# TOPIC CLASSIFIER (OpenAI) - d√πng ƒë·ªÉ ki·ªÉm tra n·∫øu b·∫°n mu·ªën reject non-travel
# -------------------------
def is_travel_related_via_gpt(user_text):
    """
    D√πng OpenAI ƒë·ªÉ x√°c ƒë·ªãnh xem c√¢u h·ªèi c√≥ li√™n quan ƒë·∫øn du l·ªãch kh√¥ng.
    Tr·∫£ v·ªÅ True n·∫øu li√™n quan, False n·∫øu kh√¥ng.
    """
    if not client:
        return True  # n·∫øu kh√¥ng c√≥ API key th√¨ cho qua lu√¥n

    try:
        prompt = f"""
B·∫°n l√† b·ªô ph√¢n lo·∫°i ch·ªß ƒë·ªÅ th√¥ng minh.
H√£y x√°c ƒë·ªãnh xem c√¢u sau c√≥ li√™n quan ƒë·∫øn lƒ©nh v·ª±c *du l·ªãch Vi·ªát Nam* hay kh√¥ng.

C√°c ch·ªß ƒë·ªÅ ƒë∆∞·ª£c coi l√† li√™n quan bao g·ªìm:
- ƒë·ªãa ƒëi·ªÉm, th√†nh ph·ªë, t·ªânh, danh lam th·∫Øng c·∫£nh
- th·ªùi ti·∫øt, kh√≠ h·∫≠u
- l·ªãch tr√¨nh du l·ªãch, tour, chi ph√≠, g·ª£i √Ω ƒëi·ªÉm ƒë·∫øn
- m√≥n ƒÉn ƒë·ªãa ph∆∞∆°ng, ƒë·∫∑c s·∫£n, nh√† h√†ng
- kh√°ch s·∫°n, homestay, resort
- s·ª± ki·ªán, l·ªÖ h·ªôi, vƒÉn ho√° v√πng mi·ªÅn

N·∫øu KH√îNG thu·ªôc nh·ªØng ch·ªß ƒë·ªÅ tr√™n (v√≠ d·ª•: l·∫≠p tr√¨nh, t√†i ch√≠nh, th·ªÉ thao, h·ªçc t·∫≠p...), h√£y tr·∫£ v·ªÅ JSON:
{{"related": false}}

N·∫øu C√ì li√™n quan, tr·∫£ v·ªÅ JSON:
{{"related": true}}

C√¢u ng∆∞·ªùi d√πng: "{user_text}"
"""
        response = client.chat.completions.create(
            model=DEPLOYMENT_NAME,
            messages=[{"role": "system", "content": prompt}],
            temperature=0,
            max_tokens=30,
        )
        text = response.choices[0].message.content.strip().lower()
        if '"related": true' in text:
            return True
        if '"related": false' in text:
            return False
    except Exception as e:
        print(f"[WARN] L·ªói ph√¢n lo·∫°i ch·ªß ƒë·ªÅ: {e}")
    return True  # fallback

# -------------------------
# STREAMLIT UI LAYOUT
# -------------------------
render_hero_section()
main_tab, analytics_tab = st.tabs(["üí¨ Chatbot Du l·ªãch", "üìä Th·ªëng k√™ truy v·∫•n"])

with st.sidebar:
    st.markdown("<div class='logo-title'><img src='https://img.icons8.com/emoji/48/000000/cloud-emoji.png'/> <h2>M√¢y Lang Thang</h2></div>", unsafe_allow_html=True)
    st.header("C√†i ƒë·∫∑t")
    info_options = st.multiselect("Hi·ªÉn th·ªã th√¥ng tin",
                                  ["Weather", "Food", "Map", "Photos", "Cost", "Events"],
                                  default=["Weather", "Map","Food", "Photos"])
    st.markdown("---")
    st.write("Ch·ªçn m·ª©c zoom b·∫£n ƒë·ªì:")
    map_zoom = st.slider("Zoom (4 = xa, 15 = g·∫ßn)", 4, 15, 8)
    st.markdown("---")
    st.subheader("üéôÔ∏è Voice")
    enable_voice = st.checkbox("B·∫≠t nh·∫≠p li·ªáu b·∫±ng gi·ªçng n√≥i", value=True)
    asr_lang = st.selectbox("Ng√¥n ng·ªØ nh·∫≠n d·∫°ng", ["vi-VN", "en-US"], index=0)
    tts_enable = st.checkbox("üîä ƒê·ªçc to ph·∫£n h·ªìi", value=False)
    tts_lang = st.selectbox("Ng√¥n ng·ªØ TTS", ["vi", "en"], index=0)
    st.caption("Y√™u c·∫ßu: ffmpeg + internet cho gTTS.")
    st.markdown("---")
    def status_card(title, ok=True):
        cls = "status-ok" if ok else "status-bad"
        icon = "‚úÖ" if ok else "‚ö†Ô∏è"
        st.markdown(f"<div class='{cls}'>{icon} {title}</div>", unsafe_allow_html=True)
    status_card("OpenWeatherMap", bool(OPENWEATHERMAP_API_KEY))
    status_card("Google Places", bool(GOOGLE_PLACES_KEY))
    status_card("Pixabay", bool(PIXABAY_API_KEY))
    st.markdown("---")
    st.caption("üçú Food AI: CSV local d·ªØ li·ªáu + GPT fallback")
    st.markdown("Version: v1.3 + Voice + RAG")

# initialize session messages
if "messages" not in st.session_state:
    st.session_state.messages = [{"role": "system", "content": system_prompt}]

with main_tab:
    today = datetime.now().date()
    if "quicksearch" in st.session_state:
        qs = st.session_state.quicksearch
        city_qs = qs["city"]; start_qs = qs["start"]; end_qs = qs["end"]
        people_qs = qs["people"]; style_qs = qs["style"]
        st.markdown(f"### ‚úàÔ∏è G·ª£i √Ω cho chuy·∫øn ƒëi {city_qs} ({start_qs} ‚Äì {end_qs})")
        weather_qs = get_weather_forecast(city_qs, start_qs, end_qs)
        cost_qs = estimate_cost(city_qs, (end_qs - start_qs).days + 1, people_qs, style_qs)
        colA, colB = st.columns(2)
        with colA:
            st.markdown(f"**{weather_qs}**")
            st.markdown(f"**{cost_qs}**")
        with colB:
            img = get_city_image(city_qs)
            if img:
                st.image(img, caption=f"üèûÔ∏è {city_qs}", use_container_width=True)
            lat, lon, addr = geocode_city(city_qs)
            if lat and lon:
                show_map(lat, lon, zoom=map_zoom, title=addr or city_qs)
        st.markdown("---")

    # === VOICE INPUT BAR ===
    voice_text = None
    if enable_voice:
        audio = mic_recorder(
            start_prompt="üéôÔ∏è [Chat voice] N√≥i ƒë·ªÉ nh·∫≠p c√¢u h·ªèi",
            stop_prompt="‚úãD·ª´ng nh·∫≠n di·ªán gi·ªçng n√≥i",
            just_once=True,
            key="rec_chat"
        )
        if audio:
            st.info("ƒê√£ nh·∫≠n d·ªØ li·ªáu √¢m thanh, ƒëang x·ª≠ l√Ω...")
            try:
                wav_file = write_temp_file_and_convert_to_wav(audio["bytes"])
            except Exception as e:
                wav_file = None
                st.error(f"Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi audio: {e}")
            if wav_file:
                r = sr.Recognizer()
                try:
                    with sr.AudioFile(wav_file) as source:
                        audio_data = r.record(source)
                        voice_text = r.recognize_google(audio_data, language=asr_lang)
                        st.success(f"üó£Ô∏è B·∫°n n√≥i: {voice_text}")
                        st.session_state.user_input = voice_text
                        st.rerun()
                except sr.UnknownValueError:
                    st.error("Kh√¥ng th·ªÉ nh·∫≠n di·ªán gi·ªçng n√≥i (UnknownValueError).")
                except Exception as e:
                    st.error(f"L·ªói nh·∫≠n di·ªán: {e}")

    # --- Hi·ªÉn th·ªã l·∫°i to√†n b·ªô l·ªãch s·ª≠ c≈© ---
    for msg in st.session_state.messages:
        if msg["role"] == "user":
            with st.chat_message("user", avatar="üß≠"):
                st.markdown(f"<div class='user-message'>{msg['content']}</div>", unsafe_allow_html=True)
        elif msg["role"] == "assistant":
            with st.chat_message("assistant", avatar="ü§ñ"):
                st.markdown(f"<div class='assistant-bubble'>{msg['content']}</div>", unsafe_allow_html=True)

    # Chat input (g√µ ph√≠m)
    user_input = st.chat_input("M·ªùi b·∫°n ƒë·∫∑t c√¢u h·ªèi:")
    if "user_input" in st.session_state and st.session_state.user_input:
        user_input = st.session_state.user_input

    if user_input:
        with st.chat_message("user", avatar="üß≠"):
            st.markdown(f"<div class='user-message'>{user_input}</div>", unsafe_allow_html=True)
        st.session_state.messages.append({"role": "user", "content": user_input})

        # Optional: reject non-travel topics via GPT classifier
        try:
            if not is_travel_related_via_gpt(user_input):
                msg = "Xin l·ªói üòÖ, t√¥i ch·ªâ h·ªó tr·ª£ c√°c c√¢u h·ªèi li√™n quan ƒë·∫øn **du l·ªãch Vi·ªát Nam**, nh∆∞ th·ªùi ti·∫øt, ƒë·ªãa ƒëi·ªÉm, m√≥n ƒÉn, l·ªãch tr√¨nh..."
                with st.chat_message("assistant", avatar="ü§ñ"):
                    st.markdown(msg)
                st.session_state.messages.append({"role": "assistant", "content": msg})
                # add to memory (optional)
                try:
                    add_to_memory_collection(user_input, role="user")
                    add_to_memory_collection(msg, role="assistant")
                except Exception:
                    pass
                st.stop()
        except Exception:
            # n·∫øu classifier l·ªói th√¨ ti·∫øp t·ª•c b√¨nh th∆∞·ªùng
            pass

        city_guess, start_date, end_date = extract_city_and_dates(user_input)
        days = extract_days_from_text(user_input, start_date, end_date)
        log_interaction(user_input, city_guess, start_date, end_date)

        if start_date:
            today = datetime.now().date()
            max_forecast_date = today + timedelta(days=5)
            if start_date.date() > max_forecast_date:
                st.warning(f"‚ö†Ô∏è L∆∞u √Ω: OpenWeather ch·ªâ cung c·∫•p d·ª± b√°o ~5 ng√†y. B·∫°n y√™u c·∫ßu b·∫Øt ƒë·∫ßu {start_date.strftime('%d/%m/%Y')}.")

        blocks = []
        if city_guess and "Weather" in info_options:
            blocks.append(get_weather_forecast(city_guess, start_date, end_date, user_input))
        if city_guess and "Cost" in info_options:
            blocks.append(estimate_cost(city_guess, days=days))
        if city_guess and "Events" in info_options:
            blocks.append(suggest_events(city_guess))

        for b in blocks:
            with st.chat_message("assistant", avatar="ü§ñ"):
                if isinstance(b, str):
                    st.markdown(b.replace("\\n", "\n"))
                else:
                    st.write(b)

        with st.spinner("‚è≥ ƒêang so·∫°n ph·∫£n h·ªìi..."):
            try:
                progress_text = "AI ƒëang ph√¢n t√≠ch d·ªØ li·ªáu du l·ªãch..."
                progress_bar = st.progress(0, text=progress_text)
                for percent_complete in range(0, 101, 20):
                    time.sleep(0.08)
                    progress_bar.progress(percent_complete, text=progress_text)
                progress_bar.empty()

                assistant_text = ""
                if client:
                    # --- RAG + Intent + Memory enhanced generation ---
                    try:
                        detected_intent = get_intent_via_chroma(user_input, threshold=0.18)
                        if detected_intent:
                            if detected_intent == "weather_query" and city_guess:
                                assistant_text = get_weather_forecast(city_guess, start_date, end_date, user_input)
                                assistant_text += f"\n\n( Ngu·ªìn: OpenWeatherMap )"
                            elif detected_intent == "food_query" and city_guess:
                                foods = get_local_foods_with_fallback(city_guess)
                                assistant_text = "ƒê·∫∑c s·∫£n n·ªïi b·∫≠t:\n" + "\n".join([f"- {f}" for f in foods]) if foods else "Kh√¥ng t√¨m th·∫•y ƒë·∫∑c s·∫£n trong DB."
                            elif detected_intent == "itinerary_request" and city_guess:
                                days_local = extract_days_from_text(user_input, start_date, end_date)
                                assistant_text = f"L·ªãch tr√¨nh g·ª£i √Ω cho {city_guess}, {days_local} ng√†y:\n1) Ng√†y 1: ...\n2) Ng√†y 2: ...\n3) Ng√†y 3: ..."
                            else:
                                # Unknown or not handled intent -> fallback to full generation
                                detected_intent = None
                        if not detected_intent:
                            docs, rag_context = rag_query_top_k(user_input, k=5)
                            recent_mem = recall_recent_memories(user_input, k=3)
                            recall_text = ""
                            if recent_mem:
                                recall_parts = []
                                for m in recent_mem:
                                    ts = m.get("meta", {}).get("timestamp", "")
                                    role = m.get("meta", {}).get("role", "")
                                    recall_parts.append(f"[mem:{m.get('id')}] ({role} {ts}) {m.get('text')[:400]}")
                                recall_text = "\n\n".join(recall_parts)

                            augmentation = "\n\n--- Th√¥ng tin tham kh·∫£o n·ªôi b·ªô (tr√≠ch d·∫´n): ---\n"
                            if rag_context:
                                augmentation += rag_context + "\n\n"
                            if recall_text:
                                augmentation += "\n--- Nh·ªõ g·∫ßn ƒë√¢y ---\n" + recall_text + "\n\n"
                            augmentation += "--- Khi tr·∫£ l·ªùi, n·∫øu d√πng th√¥ng tin t·ª´ ph·∫ßn tr√™n h√£y ƒë√°nh d·∫•u ngu·ªìn nh∆∞ [src:ID] ho·∫∑c [mem:ID]. ---\n"

                            temp_messages = [{"role":"system", "content": system_prompt + "\n\n" + augmentation}]
                            temp_messages.extend(st.session_state.messages[-12:])  # keep last 12 msgs
                            response = client.chat.completions.create(
                                model=DEPLOYMENT_NAME,
                                messages=temp_messages,
                                max_tokens=900,
                                temperature=0.7
                            )
                            assistant_text = response.choices[0].message.content.strip()

                        # Save to memory
                        try:
                            add_to_memory_collection(user_input, role="user", city=city_guess)
                            add_to_memory_collection(assistant_text, role="assistant", city=city_guess)
                        except Exception:
                            pass

                    except Exception as e:
                        assistant_text = f"‚ö†Ô∏è L·ªói khi t·∫°o ph·∫£n h·ªìi: {e}"
                else:
                    assistant_text = f"Xin ch√†o! T√¥i c√≥ th·ªÉ gi√∫p b·∫°n v·ªõi th√¥ng tin v·ªÅ {city_guess or 'ƒë·ªãa ƒëi·ªÉm'} ‚Äî th·ª≠ h·ªèi 'Th·ªùi ti·∫øt', 'ƒê·∫∑c s·∫£n', ho·∫∑c 'L·ªãch tr√¨nh 3 ng√†y'."

                if not assistant_text.endswith(("üå§Ô∏è‚ù§Ô∏è", "üòä", "üå∏", "üå¥", "‚ú®")):
                    assistant_text += "\n\nCh√∫c b·∫°n c√≥ chuy·∫øn ƒëi vui v·∫ª üå§Ô∏è‚ù§Ô∏è"

                st.session_state.messages.append({"role": "assistant", "content": assistant_text})

                with st.chat_message("assistant", avatar="ü§ñ"):
                    placeholder = st.empty()
                    display_text = ""
                    for char in assistant_text:
                        display_text += char
                        placeholder.markdown(display_text + "‚ñå")
                        time.sleep(0.01)
                    time.sleep(0.3)
                    placeholder.empty()
                    with st.container():
                        # highlight citations like [src:...] or [mem:...]
                        display_text_processed = re.sub(r'(\[src:[^\]]+\])', r'**\1**', assistant_text)
                        display_text_processed = re.sub(r'(\[mem:[^\]]+\])', r'**\1**', display_text_processed)
                        st.markdown("<div class='assistant-bubble'>", unsafe_allow_html=True)
                        st.markdown(display_text_processed)
                        st.markdown("</div>", unsafe_allow_html=True)
                        # --- Hi·ªÉn th·ªã ngu·ªìn tr√≠ch d·∫´n (RAG metadata) ---
                        if "last_rag_docs" in st.session_state and st.session_state["last_rag_docs"]:
                            sources = st.session_state["last_rag_docs"]
                            st.markdown("##### üìö Ngu·ªìn d·ªØ li·ªáu tham kh·∫£o:")
                                # T·∫°o expander hi·ªÉn th·ªã danh s√°ch ngu·ªìn
                            with st.expander("üìö Ngu·ªìn d·ªØ li·ªáu tham kh·∫£o"):
                                for src in sources:
                                    meta = src.get("metadata", {}) or {}
                                    title = meta.get("title", "")
                                    city = meta.get("city", "")
                                    srcname = meta.get("source", "")
                                    display_line = f"- **{src['id']}**"
                                    if title:
                                        display_line += f": *{title}*"
                                    if city:
                                        display_line += f" ‚Äì {city}"
                                    if srcname:
                                        display_line += f" _(ngu·ªìn: {srcname})_"
                                    st.markdown(display_line)


                    # === TTS (ƒë·ªçc to ph·∫£n h·ªìi) ===
                    if tts_enable:
                        try:
                            tts = gTTS(assistant_text, lang=tts_lang)
                            bio = io.BytesIO()
                            tts.write_to_fp(bio)
                            bio.seek(0)
                            b64 = base64.b64encode(bio.read()).decode()
                            st.markdown(
                                f'<div class="audio-wrapper"><audio autoplay controls><source src="data:audio/mp3;base64,{b64}" type="audio/mp3"></audio></div>',
                                unsafe_allow_html=True
                            )
                        except Exception as e:
                            st.warning(f"Kh√¥ng th·ªÉ t·∫°o audio TTS: {e}")

                st.balloons()
            except Exception as e:
                st.error(f"‚ö†Ô∏è L·ªói khi g·ªçi OpenAI: {e}")

        lat, lon, addr = (None, None, None)
        if city_guess:
            lat, lon, addr = geocode_city(city_guess)
        cols = st.columns([2, 3])
        with cols[0]:
            if "Map" in info_options:
                show_map(lat, lon, zoom=map_zoom, title=addr or city_guess)
            if "Photos" in info_options:
                img = get_city_image(city_guess)
                if img:
                    st.image(img, caption=f"üèûÔ∏è {city_guess}", use_container_width=True)
                else:
                    st.info("Kh√¥ng t√¨m th·∫•y ·∫£nh minh h·ªça.")
        with cols[1]:
            if "Food" in info_options:
                st.subheader(f"üçΩÔ∏è ·∫®m th·ª±c & Nh√† h√†ng t·∫°i {city_guess or 'ƒë·ªãa ƒëi·ªÉm'}")
                foods = get_local_foods_with_fallback(city_guess) if city_guess else []
                if foods:
                    st.markdown("#### ü•ò ƒê·∫∑c s·∫£n n·ªïi b·∫≠t")
                    food_images = get_food_images(foods)
                    img_cols = st.columns(min(len(food_images), 4))
                    for i, item in enumerate(food_images):
                        with img_cols[i % len(img_cols)]:
                            if item["image"]:
                                st.image(item["image"], caption=item["name"], use_container_width=True)
                            else:
                                st.write(f"- {item['name']}")
                else:
                    st.info("Kh√¥ng t√¨m th·∫•y m√≥n ƒë·∫∑c tr∆∞ng (CSV/GPT fallback kh√¥ng tr·∫£ k·∫øt qu·∫£).")
            if city_guess:
                st.markdown("#### üç¥ Nh√† h√†ng g·ª£i √Ω")
                restaurants = get_restaurants(city_guess, limit=5)
                if restaurants:
                    for r in restaurants:
                        if isinstance(r, dict) and r.get("error"):
                            st.write(f"‚ö†Ô∏è {r.get('error')}")
                        else:
                            name = r.get("name") or r.get("place_name") or str(r)
                            rating = r.get("rating", "")
                            addr_text = r.get("address", r.get("formatted_address", ""))
                            maps_url = r.get("maps_url", "")
                            st.markdown(f"- **{name}** {f'‚Ä¢ ‚≠ê {rating}' if rating else ''}  \n  {addr_text}  " + (f"[B·∫£n ƒë·ªì]({maps_url})" if maps_url else ""))
                else:
                    st.info("Kh√¥ng c√≥ d·ªØ li·ªáu nh√† h√†ng (CSV/Google Places fallback).")

with analytics_tab:
    st.header("üìä Th·ªëng k√™ truy v·∫•n (g·∫ßn ƒë√¢y)")
    with st.expander("üóëÔ∏è X√≥a l·ªãch s·ª≠ truy v·∫•n"):
        st.warning("‚ö†Ô∏è Thao t√°c n√†y s·∫Ω x√≥a to√†n b·ªô l·ªãch s·ª≠ truy v·∫•n ƒë√£ l∆∞u trong c∆° s·ªü d·ªØ li·ªáu (SQLite). Kh√¥ng th·ªÉ ho√†n t√°c.")
        confirm_delete = st.checkbox("T√¥i hi·ªÉu v√† mu·ªën x√≥a to√†n b·ªô l·ªãch s·ª≠ truy v·∫•n", value=False)
        if confirm_delete:
            if st.button("‚úÖ X√°c nh·∫≠n x√≥a to√†n b·ªô l·ªãch s·ª≠"):
                try:
                    conn = sqlite3.connect(DB_PATH)
                    cur = conn.cursor()
                    cur.execute("DELETE FROM interactions")
                    conn.commit()
                    conn.close()
                    st.success("‚úÖ ƒê√£ x√≥a to√†n b·ªô l·ªãch s·ª≠ truy v·∫•n.")
                except Exception as e:
                    st.error(f"‚ö†Ô∏è L·ªói khi x√≥a d·ªØ li·ªáu: {e}")
        else:
            st.info("üëâ H√£y tick v√†o √¥ x√°c nh·∫≠n tr∆∞·ªõc khi x√≥a l·ªãch s·ª≠.")
    try:
        conn = sqlite3.connect(DB_PATH)
        df_logs = pd.read_sql("SELECT * FROM interactions ORDER BY timestamp DESC LIMIT 1000", conn)
        conn.close()
        total = int(df_logs.shape[0]) if not df_logs.empty else 0
        st.metric("T·ªïng t∆∞∆°ng t√°c", total)
        if not df_logs.empty:
            df_logs['timestamp_dt'] = pd.to_datetime(df_logs['timestamp'])
            df_logs['date'] = df_logs['timestamp_dt'].dt.date
            series = df_logs.groupby('date').size().reset_index(name='queries')
            fig = px.bar(series, x='date', y='queries', title='üìà S·ªë truy v·∫•n m·ªói ng√†y', color='queries', color_continuous_scale='Blues')
            st.plotly_chart(fig, use_container_width=True)
            top_cities = df_logs['city'].fillna("Unknown").value_counts().reset_index()
            top_cities.columns = ['city', 'count']
            if not top_cities.empty:
                fig2 = px.bar(top_cities.head(10), x='city', y='count', title='üìç Top ƒë·ªãa ƒëi·ªÉm ƒë∆∞·ª£c h·ªèi', color='count', color_continuous_scale='Viridis')
                st.plotly_chart(fig2, use_container_width=True)
            st.dataframe(df_logs[["timestamp", "user_input", "city"]])
        else:
            st.info("Ch∆∞a c√≥ truy v·∫•n n√†o ƒë∆∞·ª£c ghi nh·∫≠n.")
    except Exception as e:
        st.warning(f"L·ªói ƒë·ªçc d·ªØ li·ªáu: {e}")

st.markdown("---")
st.markdown("<div class='small-muted'>Tip: B·∫°n c√≥ th·ªÉ y√™u c·∫ßu c·ª• th·ªÉ nh∆∞ 'L·ªãch tr√¨nh 3 ng√†y ·ªü H·ªôi An', 'ƒê·∫∑c s·∫£n Sapa', ho·∫∑c 'Th·ªùi ti·∫øt ƒê√† N·∫µng 2025-10-20 ƒë·∫øn 2025-10-22'.</div>", unsafe_allow_html=True)


# -------------------------
# Optional: seeding vietnam_travel collection from CSV
# -------------------------
def seed_vietnam_travel_from_csv(path="data/vietnam_travel_docs.csv"):
    if chroma_travel_col is None:
        print("Chroma travel collection not ready")
        return
    if not os.path.exists(path):
        print("Seed file not found:", path)
        return
    try:
        docs = []
        metas = []
        ids = []
        import csv
        with open(path, newline='', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                text = row.get("text") or row.get("description") or ""
                docs.append(text)
                metas.append({"title": row.get("title",""), "city": row.get("city",""), "source": row.get("source","")})
                ids.append(row.get("id") or f"doc_{uuid.uuid4().hex[:8]}")
        chroma_travel_col.add(documents=docs, metadatas=metas, ids=ids)
        print(f"Seeded {len(docs)} docs to vietnam_travel")
    except Exception as e:
        print("Seed error:", e)

# You can call seed_vietnam_travel_from_csv() manually in a session if needed.
# Example: seed_vietnam_travel_from_csv("data/vietnam_travel_docs.csv")

